{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "In this notebook, we will test multiple model and evaluate to choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "X = pd.read_pickle('PKL/X_train.pkl')\n",
    "y = pd.read_pickle('PKL/Y_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "We will split the train data once more. It's because this is a competition dataset and we actually don't have the 'test' score result. So we will use the test set we created from the initial training set as a holdout set to actually see our performance of the final model. The final test set, which we don't have the labels for, will be used to make a prediction in the final testing notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 13, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning all categorical features to dummies \n",
    "X_train_ohe = pd.get_dummies(X_train)\n",
    "X_test_ohe = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "# Check if training and testing sets have the same features\n",
    "if X_train_ohe.shape[1] != X_test_ohe.shape[1]:\n",
    "    print([x for x in X_train_ohe.columns if x not in X_test_ohe.columns])\n",
    "    print([x for x in X_test_ohe.columns if x not in X_train_ohe.columns])\n",
    "else: \n",
    "    print ('Good to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If they are not the same, add the column with 0s and fix the order\n",
    "# X_test_ohe[colname] = 0\n",
    "# X_test_ohe = X_test_ohe[X_train_ohe.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance Issue\n",
    "Our dataset has high class imbalance issue. We will mostly deal with this by setting the class weight within each model, otherwise mentioned (in some cases where imbalance weight is not adequately dealt with by algorithm we test with SMOTE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Our target is multi-class with imbalance issue. To focus on the imbalance of minority classes, we will use balanced accuracy score. This computes the average accuracy score weighted by the inverse prevalence of the true class. So it accounts for the imbalance for rigorously then the weighted f1 score, which only takes the number of positive cases into account. We will also look at the weighted f1 score to capture the predictive performance for overall classes. It calculates the f1 score for each class and find the average weighted by the number of actual positive cases in each class, so naturally penalizes if minority recall is low.\n",
    "\n",
    "In terms of prediction within each class, we rather want to overpredict 'needs repair' or 'non functional' cases (minorities) than the functional cases. Because the condition of the well is crucial for survival of surrounding population. Specifically, we want the recall of the non functional and needs repair cases to be high because false positive of minority classes is better than missing those actually positive classes. I will look at this breakdown using the classification report.\n",
    "\n",
    "Additionally we will plot confusion matrix to understand some of the scores better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score, plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier\n",
    "We'll first create a dummy classifier as a baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping score\n",
    "score_keeper = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.444 / Test Accuracy:  0.336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummyc = DummyClassifier(strategy = 'stratified') # using the default stratified strategy\n",
    "dummyc.fit(X_train_ohe, y_train)\n",
    "y_pred = dummyc.predict(X_test_ohe)\n",
    "\n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['baseline'] = (f1_test, acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.54      0.53      0.54      4822\n",
      "functional needs repair       0.09      0.08      0.08       678\n",
      "         non functional       0.38      0.39      0.39      3410\n",
      "\n",
      "               accuracy                           0.44      8910\n",
      "              macro avg       0.34      0.34      0.34      8910\n",
      "           weighted avg       0.44      0.44      0.44      8910\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(dummyc, X_test_ohe, y_test, xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stratified dummy classifier shows the weighted F1 score around .45 but less balanced accuracy. Dummy classifier is consistently wrong on all cases but recall for minority classes are especially bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "Now we will run K-Nearest Neighbors using GridSearchCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "For KNN, all feature values need to be standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train_scaled = scale.fit_transform(X_train_ohe)\n",
    "X_test_scaled = scale.transform(X_test_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal hyperparameters using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 16.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 3} :  0.6165279631918787\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': range(1, 16, 2), # setting K\n",
    "}\n",
    "\n",
    "knc = KNeighborsClassifier(weights = 'distance') \n",
    "knc_g = GridSearchCV(knc, params, cv = 5, scoring = 'balanced_accuracy', verbose = 1, n_jobs = -1)\n",
    "knc_g.fit(X_train_scaled, y_train)\n",
    "print(knc_g.best_params_, ': ', knc_g.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model \n",
    "#mod = open('PKL/knn_gsc.pkl', 'wb')\n",
    "#pickle.dump(knc_g.best_estimator_, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "#knc_g = pickle.load(open('PKL/knn_gsc.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.741 / Test Accuracy:  0.622\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.78      0.81      0.80      4822\n",
      "functional needs repair       0.39      0.32      0.35       678\n",
      "         non functional       0.75      0.74      0.74      3410\n",
      "\n",
      "               accuracy                           0.74      8910\n",
      "              macro avg       0.64      0.62      0.63      8910\n",
      "           weighted avg       0.74      0.74      0.74      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN performance on the test set\n",
    "y_pred = knc_g.predict(X_test_scaled)    \n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['knn_gsc'] = (f1_test, acc_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = knc_g.predict(X_train_scaled)    \n",
    "f1_test = round(f1_score(y_train, y_train_pred, average = 'weighted'), 3)\n",
    "f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall improvement from the dummy model, but the recall of needs repair class is still low. Looking at training score (.99) shows that it's highly overfitting. In this document we'll see if different optimization method finds a better hyperparameter. \n",
    "In 030B file, we explore more into limiting features using random forest feature selection for KNN as KNN does not select features and can make the model messy. As a summary, after Random Forest feature selection, the performance didn't improve, but also didn't drop. So we know for KNN those extra features were unnecessarily complicating our model. For the sake of keeping it consistent with the rest of models, we will keep all features (they have been already selected based on intuition in the EDA notebook) for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Method\n",
    "Now we want to try different optimization method to make sure we have the best hyperparmeter for KNN. This time we'll use optuna to explore even more hyperparameters. We'll cap the time to what it took to run the GridSearch above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-20 11:40:00,703] Trial 0 finished with value: 0.6096783381319073 and parameters: {'n_neighbors': 18, 'algorithm': 'kd_tree', 'leaf_size': 53, 'p': 2}. Best is trial 0 with value: 0.6096783381319073.\n",
      "[I 2020-08-20 11:44:42,230] Trial 1 finished with value: 0.6188363249223392 and parameters: {'n_neighbors': 30, 'algorithm': 'ball_tree', 'leaf_size': 22, 'p': 1}. Best is trial 1 with value: 0.6188363249223392.\n",
      "[I 2020-08-20 11:48:14,834] Trial 2 finished with value: 0.6245422567048429 and parameters: {'n_neighbors': 19, 'algorithm': 'kd_tree', 'leaf_size': 23, 'p': 1}. Best is trial 2 with value: 0.6245422567048429.\n",
      "[I 2020-08-20 11:52:42,863] Trial 3 finished with value: 0.6352037888827585 and parameters: {'n_neighbors': 4, 'algorithm': 'ball_tree', 'leaf_size': 49, 'p': 1}. Best is trial 3 with value: 0.6352037888827585.\n",
      "[I 2020-08-20 11:57:22,402] Trial 4 finished with value: 0.6245422567048429 and parameters: {'n_neighbors': 19, 'algorithm': 'ball_tree', 'leaf_size': 26, 'p': 1}. Best is trial 3 with value: 0.6352037888827585.\n"
     ]
    }
   ],
   "source": [
    "def find_hyperp_KNN(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 31)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    leaf_size = trial.suggest_int('leaf_size', 2, 60)\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "    knc = KNeighborsClassifier(weights = 'distance', \n",
    "                             n_neighbors = n_neighbors, \n",
    "                             algorithm = algorithm, \n",
    "                             leaf_size = leaf_size, \n",
    "                             p = p)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(knc, X_train_scaled, y_train, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "knn_study = optuna.create_study(direction='maximize')\n",
    "knn_study.optimize(find_hyperp_KNN, timeout = 16*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the study \n",
    "#mod = open('PKL/knn_study.pkl', 'wb')\n",
    "#pickle.dump(knn_study, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the study\n",
    "#knn_study = pickle.load(open('PKL/knn_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.753 / Test Accuracy:  0.631\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.82      0.81      4822\n",
      "functional needs repair       0.42      0.32      0.36       678\n",
      "         non functional       0.76      0.75      0.76      3410\n",
      "\n",
      "               accuracy                           0.76      8910\n",
      "              macro avg       0.66      0.63      0.64      8910\n",
      "           weighted avg       0.75      0.76      0.75      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the best params on the test set\n",
    "knc_opt = KNeighborsClassifier(**knn_study.best_params, weights = 'distance')\n",
    "knc_opt.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knc_opt.predict(X_test_scaled)    \n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['knn_opt'] = (f1_test, acc_test)\n",
    "#plot_confusion_matrix(knc_opt, X_test_scaled, y_test, xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod = open('PKL/knc_opt_model.pkl', 'wb')\n",
    "#pickle.dump(knc_opt, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score for the needs repair class is still low but the overall performance and recall for non-functional improved slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "Since Optuna performance was better above, now we'll try running random forest using Optuna. Since we have a lot of features, tree-based model might deal better by ignoring not important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-20 13:54:23,185] Trial 2689 finished with value: 0.6706923275206784 and parameters: {'n_estimators': 318, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 2689 with value: 0.6706923275206784.\n",
      "[I 2020-08-20 13:55:06,902] Trial 2690 finished with value: 0.6714127643076309 and parameters: {'n_estimators': 313, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 26}. Best is trial 2690 with value: 0.6714127643076309.\n",
      "[I 2020-08-20 13:55:50,525] Trial 2691 finished with value: 0.6705303748728861 and parameters: {'n_estimators': 327, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 2690 with value: 0.6714127643076309.\n",
      "[I 2020-08-20 13:56:33,946] Trial 2692 finished with value: 0.670188901813268 and parameters: {'n_estimators': 324, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 2690 with value: 0.6714127643076309.\n",
      "[I 2020-08-20 13:57:20,827] Trial 2693 finished with value: 0.6688301611157418 and parameters: {'n_estimators': 346, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 26}. Best is trial 2690 with value: 0.6714127643076309.\n",
      "[I 2020-08-20 13:58:05,593] Trial 2694 finished with value: 0.6707084057892811 and parameters: {'n_estimators': 335, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 2690 with value: 0.6714127643076309.\n",
      "[I 2020-08-20 13:58:50,940] Trial 2695 finished with value: 0.6715929093499989 and parameters: {'n_estimators': 332, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 2695 with value: 0.6715929093499989.\n",
      "[I 2020-08-20 13:59:38,192] Trial 2696 finished with value: 0.673050330428271 and parameters: {'n_estimators': 340, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 27}. Best is trial 2696 with value: 0.673050330428271.\n",
      "[I 2020-08-20 14:00:25,513] Trial 2697 finished with value: 0.6688709099891964 and parameters: {'n_estimators': 330, 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 2696 with value: 0.673050330428271.\n",
      "[I 2020-08-20 14:01:15,281] Trial 2698 finished with value: 0.6818715158298259 and parameters: {'n_estimators': 331, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 26}. Best is trial 2698 with value: 0.6818715158298259.\n",
      "[I 2020-08-20 14:02:03,421] Trial 2699 finished with value: 0.6809174876853422 and parameters: {'n_estimators': 335, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 2698 with value: 0.6818715158298259.\n",
      "[I 2020-08-20 14:02:54,259] Trial 2700 finished with value: 0.6818223041043876 and parameters: {'n_estimators': 333, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 28}. Best is trial 2698 with value: 0.6818715158298259.\n",
      "[I 2020-08-20 14:03:44,001] Trial 2701 finished with value: 0.6814143809803455 and parameters: {'n_estimators': 333, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 26}. Best is trial 2698 with value: 0.6818715158298259.\n",
      "[I 2020-08-20 14:04:33,797] Trial 2702 finished with value: 0.681563413643566 and parameters: {'n_estimators': 336, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 26}. Best is trial 2698 with value: 0.6818715158298259.\n",
      "[I 2020-08-20 14:05:23,057] Trial 2703 finished with value: 0.6805585055509416 and parameters: {'n_estimators': 334, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 26}. Best is trial 2698 with value: 0.6818715158298259.\n",
      "[I 2020-08-20 14:06:09,323] Trial 2704 finished with value: 0.6830087541194512 and parameters: {'n_estimators': 324, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 2704 with value: 0.6830087541194512.\n",
      "[I 2020-08-20 14:07:10,319] Trial 2705 finished with value: 0.684610301117163 and parameters: {'n_estimators': 365, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 34}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:08:16,006] Trial 2706 finished with value: 0.6838928953222834 and parameters: {'n_estimators': 376, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 35}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:09:19,770] Trial 2707 finished with value: 0.6822327610920029 and parameters: {'n_estimators': 384, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 34}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:10:24,215] Trial 2708 finished with value: 0.6819277841811313 and parameters: {'n_estimators': 373, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 35}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:11:29,173] Trial 2709 finished with value: 0.6833404045881412 and parameters: {'n_estimators': 370, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 36}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:12:33,184] Trial 2710 finished with value: 0.6824179579650645 and parameters: {'n_estimators': 370, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 37}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:13:40,463] Trial 2711 finished with value: 0.6840401606863071 and parameters: {'n_estimators': 376, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 37}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:14:46,297] Trial 2712 finished with value: 0.6824039240133307 and parameters: {'n_estimators': 369, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 38}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:15:51,893] Trial 2713 finished with value: 0.6828986080495666 and parameters: {'n_estimators': 376, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 37}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:16:58,716] Trial 2714 finished with value: 0.6816471744115548 and parameters: {'n_estimators': 367, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 38}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:18:04,064] Trial 2715 finished with value: 0.6817156475658971 and parameters: {'n_estimators': 376, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 38}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:19:11,442] Trial 2716 finished with value: 0.6830894783250352 and parameters: {'n_estimators': 381, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 39}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:20:20,984] Trial 2717 finished with value: 0.6819809184237176 and parameters: {'n_estimators': 385, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 39}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:21:34,166] Trial 2718 finished with value: 0.684179227273921 and parameters: {'n_estimators': 410, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 38}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:22:53,700] Trial 2719 finished with value: 0.6841210698380786 and parameters: {'n_estimators': 443, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 37}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:24:12,408] Trial 2720 finished with value: 0.6825827946346495 and parameters: {'n_estimators': 448, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 38}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:25:33,555] Trial 2721 finished with value: 0.6830597104896649 and parameters: {'n_estimators': 444, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 39}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:27:02,795] Trial 2722 finished with value: 0.682206583064459 and parameters: {'n_estimators': 444, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 45}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:28:31,085] Trial 2723 finished with value: 0.6830405502424312 and parameters: {'n_estimators': 454, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 45}. Best is trial 2705 with value: 0.684610301117163.\n",
      "[I 2020-08-20 14:30:00,353] Trial 2724 finished with value: 0.6817692455759252 and parameters: {'n_estimators': 443, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 46}. Best is trial 2705 with value: 0.684610301117163.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-28ac92c43f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#rfc_study = optuna.create_study(direction='maximize')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mrfc_study\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_hyperparam_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# run it for 3 hours\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 self._optimize_sequential(\n\u001b[1;32m--> 292\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m                 )\n\u001b[0;32m    294\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    652\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;31m# type: (...) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-28ac92c43f84>\u001b[0m in \u001b[0;36mfind_hyperparam_rf\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     16\u001b[0m                              max_features = max_features)\n\u001b[0;32m     17\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_ohe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'balanced_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 248\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def find_hyperparam_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 700)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    #min_samples_split = trial.suggest_int('min_samples_split', 0, 10)\n",
    "    #min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 15)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    class_weight = trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\n",
    "    max_features = trial.suggest_int('max_features', 2, 100)\n",
    "    rfc = RandomForestClassifier(oob_score = True, \n",
    "                             n_estimators = n_estimators, \n",
    "                             max_depth = max_depth, \n",
    "                             #min_samples_split = min_samples_split, \n",
    "                             #min_samples_leaf = min_samples_leaf, \n",
    "                             criterion = criterion, \n",
    "                             class_weight = class_weight, \n",
    "                             max_features = max_features)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(rfc, X_train_ohe, y_train, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "#rfc_study = optuna.create_study(direction='maximize')\n",
    "rfc_study.optimize(find_hyperparam_rf, timeout = 60*60*3) # run it for 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the study\n",
    "#mod = open('PKL/rfc_study.pkl', 'wb')\n",
    "#pickle.dump(rfc_study, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the study\n",
    "#rfc_study = pickle.load(open('PKL/rfc_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.731 / Test Accuracy:  0.694\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score = True, \n",
    "                            **rfc_study.best_params)\n",
    "\n",
    "rf.fit(X_train_ohe, y_train)\n",
    "y_pred = rf.predict(X_test_ohe)  \n",
    "\n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['rf_opt'] = (f1_test, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.80      0.75      0.77      4822\n",
      "functional needs repair       0.28      0.66      0.39       678\n",
      "         non functional       0.83      0.67      0.74      3410\n",
      "\n",
      "               accuracy                           0.71      8910\n",
      "              macro avg       0.63      0.69      0.63      8910\n",
      "           weighted avg       0.77      0.71      0.73      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#plot_confusion_matrix(rf, X_test_ohe, y_test, xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better performance in predicting the positive minority cases even though overall F1 score has dropped. This model seems to be weighing the minority recall better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod = open('PKL/rf_model.pkl', 'wb')\n",
    "#pickle.dump(rf, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "Now we'll run XGBoost with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-20 17:33:16,847] Trial 35 finished with value: 0.6520639628197994 and parameters: {'eta': 0.0012988334911475854, 'max_depth': 14, 'subsample': 0.5022969261179748, 'sampling_method': 'uniform', 'colsample_bytree': 0.5552048637599156}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 17:36:37,911] Trial 36 finished with value: 0.6379617145267552 and parameters: {'eta': 0.005506618589988977, 'max_depth': 10, 'subsample': 0.7426994857657646, 'sampling_method': 'uniform', 'colsample_bytree': 0.6534764712400242}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 17:38:03,222] Trial 37 finished with value: 0.6364513528499576 and parameters: {'eta': 0.0024182275440335532, 'max_depth': 13, 'subsample': 0.6457173136132873, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.16274388139190094}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 17:39:47,808] Trial 38 finished with value: 0.5642491098417104 and parameters: {'eta': 0.003606550276964796, 'max_depth': 3, 'subsample': 0.5571183335915042, 'sampling_method': 'uniform', 'colsample_bytree': 0.9997272409249164}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 17:41:17,026] Trial 39 finished with value: 0.6274883953914381 and parameters: {'eta': 0.011500312910329697, 'max_depth': 9, 'subsample': 0.7747127374079784, 'sampling_method': 'uniform', 'colsample_bytree': 0.282283547595696}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 17:46:36,881] Trial 40 finished with value: 0.6535909387979737 and parameters: {'eta': 0.0015041454459306044, 'max_depth': 14, 'subsample': 0.45207287162037074, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.7239719013111587}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 17:52:07,111] Trial 41 finished with value: 0.6527442636142536 and parameters: {'eta': 0.0015041776858719924, 'max_depth': 14, 'subsample': 0.4601044519674046, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.7565813583845957}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 17:57:20,945] Trial 42 finished with value: 0.644850252049093 and parameters: {'eta': 0.0022265127142278283, 'max_depth': 12, 'subsample': 0.3960121046864914, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.8903259290116438}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 18:03:59,373] Trial 43 finished with value: 0.6564695482692215 and parameters: {'eta': 0.0013698191380845676, 'max_depth': 15, 'subsample': 0.61994395914628, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.8031405417437968}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 18:07:43,520] Trial 44 finished with value: 0.6515887787604164 and parameters: {'eta': 0.0013082422870318738, 'max_depth': 14, 'subsample': 0.6254972331335988, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.47719469374804696}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 18:12:37,752] Trial 45 finished with value: 0.6497809603682728 and parameters: {'eta': 0.1374703700617724, 'max_depth': 13, 'subsample': 0.538007016586364, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.6854247207927573}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 18:17:14,506] Trial 46 finished with value: 0.6473118731423442 and parameters: {'eta': 0.0014078440316726004, 'max_depth': 12, 'subsample': 0.8421026513901636, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.787472244301344}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 18:21:33,988] Trial 47 finished with value: 0.6523153327162425 and parameters: {'eta': 0.004765499717593206, 'max_depth': 14, 'subsample': 0.4754986306861918, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.5643885802877904}. Best is trial 31 with value: 0.6571135182900025.\n",
      "[I 2020-08-20 18:28:23,549] Trial 48 finished with value: 0.6578844904553305 and parameters: {'eta': 0.001038709382469881, 'max_depth': 15, 'subsample': 0.6665960477032411, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.8626151873679676}. Best is trial 48 with value: 0.6578844904553305.\n",
      "[I 2020-08-20 18:31:31,498] Trial 49 finished with value: 0.6526396159681149 and parameters: {'eta': 0.33619289373315103, 'max_depth': 15, 'subsample': 0.5886417368512464, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.36107562931081577}. Best is trial 48 with value: 0.6578844904553305.\n"
     ]
    }
   ],
   "source": [
    "def find_hyperparam(trial):\n",
    "    eta = trial.suggest_loguniform('eta', 0.001, 0.5)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 15)\n",
    "    #min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_loguniform('subsample', 0.1, 1.0)\n",
    "    sampling_method = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.1, 1.0)\n",
    "    xgbc = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                             eta = eta, \n",
    "                             num_boost_round = 999, \n",
    "                             early_stopping_rounds=10, \n",
    "                             max_depth = max_depth, \n",
    "                             #min_child_weight = min_child_weight, \n",
    "                             subsample = subsample, \n",
    "                             sampling_method = sampling_method, \n",
    "                             colsample_bytree = colsample_bytree)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train_ohe, y_train, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "#xgb_study = optuna.create_study(direction='maximize')\n",
    "xgb_study.optimize(find_hyperparam, timeout = 60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving study\n",
    "#mod = open('PKL/xgb_study.pkl', 'wb')\n",
    "#pickle.dump(xgb_study, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the study\n",
    "#xgb_study = pickle.load(open('PKL/xgb_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.802 / Test Accuracy:  0.664\n"
     ]
    }
   ],
   "source": [
    "xgbc = xgb.XGBClassifier(**xgb_study.best_params, n_jobs= -1, verbosity=1)\n",
    "\n",
    "xgbc.fit(X_train_ohe, y_train)\n",
    "\n",
    "y_pred = xgbc.predict(X_test_ohe)    \n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['XGB_opt_1'] = (f1_test, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.89      0.85      4822\n",
      "functional needs repair       0.59      0.31      0.40       678\n",
      "         non functional       0.84      0.79      0.81      3410\n",
      "\n",
      "               accuracy                           0.81      8910\n",
      "              macro avg       0.75      0.66      0.69      8910\n",
      "           weighted avg       0.80      0.81      0.80      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#plot_confusion_matrix(xgbc, X_test_ohe, y_test, xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/xgbc_model.pkl', 'wb')\n",
    "#pickle.dump(xgbc, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top two classes are doing so much better, but the minority class recall score dropped significantly. We'll try to oversample minority classes and try again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote and XGBoost\n",
    "In order to control for class imbalance in XGBoost, we'll try to oversample using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_res, y_train_res = smote.fit_sample(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparam2(trial):\n",
    "    \n",
    "    eta = trial.suggest_loguniform(\"eta\", 1e-8, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_loguniform(\"subsample\", 1e-8, 1.0)\n",
    "    sampling_method = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    colsample_bytree = trial.suggest_loguniform(\"colsample_bytree\", 1e-8, 1.0)\n",
    "    num_parallel_tree = trial.suggest_int('num_parallel_tree', 1, 10)\n",
    "    max_delta_step = trial.suggest_int('max_delta_step', 0, 1)\n",
    "    xgbc = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                             eta = eta, \n",
    "                             num_boost_round = 999, \n",
    "                             early_stopping_rounds=10, \n",
    "                             max_depth = max_depth, \n",
    "                             min_child_weight = min_child_weight, \n",
    "                             subsample = subsample, \n",
    "                             sampling_method = sampling_method, \n",
    "                             colsample_bytree = colsample_bytree, \n",
    "                             num_parallel_tree = num_parallel_tree, \n",
    "                             max_delta_step = max_delta_step,\n",
    "                             )\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train_res, y_train_res, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-20 20:48:25,348] Trial 25 finished with value: 0.6816795334217501 and parameters: {'eta': 1.0888614100546952e-08, 'max_depth': 10, 'min_child_weight': 0, 'subsample': 0.0014302855677198964, 'sampling_method': 'uniform', 'colsample_bytree': 0.9687720546858777}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:51:45,732] Trial 26 finished with value: 0.7684001712683761 and parameters: {'eta': 2.2278725673155052e-08, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.010231994439737336, 'sampling_method': 'uniform', 'colsample_bytree': 0.9810484117774854}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:53:01,562] Trial 27 finished with value: 0.7843421718981711 and parameters: {'eta': 1.1329412014478851e-08, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.023601978898212635, 'sampling_method': 'uniform', 'colsample_bytree': 0.2436145769144805}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:53:24,208] Trial 28 finished with value: 0.5879325366583525 and parameters: {'eta': 4.882376436772755e-08, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.020032098051329324, 'sampling_method': 'uniform', 'colsample_bytree': 0.004579666578240327}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:54:16,350] Trial 29 finished with value: 0.7613294441026681 and parameters: {'eta': 5.439709023531179e-08, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.021319489271122257, 'sampling_method': 'uniform', 'colsample_bytree': 0.19698895815338102}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:54:44,626] Trial 30 finished with value: 0.6793320262635144 and parameters: {'eta': 1.491632139521805e-06, 'max_depth': 10, 'min_child_weight': 0, 'subsample': 0.2881094428078656, 'sampling_method': 'uniform', 'colsample_bytree': 0.011328358894830665}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:55:28,933] Trial 31 finished with value: 0.7527456318776728 and parameters: {'eta': 8.39508992222306e-08, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.02073845305424294, 'sampling_method': 'uniform', 'colsample_bytree': 0.12742246716835756}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:56:33,356] Trial 32 finished with value: 0.7743721555454289 and parameters: {'eta': 3.827844269123628e-08, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.024877141179271953, 'sampling_method': 'uniform', 'colsample_bytree': 0.2415687866674332}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:56:59,582] Trial 33 finished with value: 0.5759165629377454 and parameters: {'eta': 1.5653589753115523e-08, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.0010294496214885407, 'sampling_method': 'uniform', 'colsample_bytree': 0.04077949555839628}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:58:16,821] Trial 34 finished with value: 0.7866198157263622 and parameters: {'eta': 1.3324239908383854e-07, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.03815406824553536, 'sampling_method': 'uniform', 'colsample_bytree': 0.24199349006184526}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 20:59:37,961] Trial 35 finished with value: 0.7975377517705845 and parameters: {'eta': 2.226959429225286e-07, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.055669688108227706, 'sampling_method': 'uniform', 'colsample_bytree': 0.24417794419646446}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:00:03,696] Trial 36 finished with value: 0.6772486604040918 and parameters: {'eta': 2.679824686703846e-07, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.2777740446045674, 'sampling_method': 'uniform', 'colsample_bytree': 0.011386953288910762}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:00:44,461] Trial 37 finished with value: 0.7636364936728309 and parameters: {'eta': 1.5503583333685846e-06, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.060340384125706865, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.07143774282947854}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:01:14,252] Trial 38 finished with value: 0.3333333333333333 and parameters: {'eta': 2.881946491996114e-07, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 6.672243403380855e-06, 'sampling_method': 'uniform', 'colsample_bytree': 0.47428658073171326}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:01:36,445] Trial 39 finished with value: 0.5593143984958474 and parameters: {'eta': 3.861803964192897e-06, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.06935990515800011, 'sampling_method': 'uniform', 'colsample_bytree': 0.000780759223630319}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:02:34,289] Trial 40 finished with value: 0.7953071473655625 and parameters: {'eta': 4.018853178759227e-07, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.328580729209501, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.08384317352652032}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:03:31,864] Trial 41 finished with value: 0.7949276943366061 and parameters: {'eta': 2.227369025031633e-07, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.3518387029558143, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.07974091724925234}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:04:24,267] Trial 42 finished with value: 0.7894993114047185 and parameters: {'eta': 2.248820556425612e-07, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.3389735242313587, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.06971927102525437}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:04:53,236] Trial 43 finished with value: 0.6940173571943381 and parameters: {'eta': 3.862106149408977e-07, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.3638480637748515, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.01556932763034646}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:05:30,384] Trial 44 finished with value: 0.7644815425790903 and parameters: {'eta': 9.347335393403919e-07, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.14839067121922359, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.06511115830753561}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:05:53,202] Trial 45 finished with value: 0.6233924268557868 and parameters: {'eta': 3.5848745703877726e-06, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.30948151382131933, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.004224021004747684}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:06:32,021] Trial 46 finished with value: 0.7395684138561143 and parameters: {'eta': 6.364588150596661e-07, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.5477286087230921, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.03065855249147602}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:07:13,193] Trial 47 finished with value: 0.7722499919162298 and parameters: {'eta': 1.7161380360668043e-07, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.09506532391979723, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.08216985674732251}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:07:35,575] Trial 48 finished with value: 0.3333333333333333 and parameters: {'eta': 8.964611531456642e-06, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 6.643833462557961e-07, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.00047300224251969517}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:07:59,197] Trial 49 finished with value: 0.639975125872916 and parameters: {'eta': 1.095245850001962e-06, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.9980890886839883, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.007948234172744373}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:08:21,367] Trial 50 finished with value: 0.3333333333333333 and parameters: {'eta': 1.771779036697666e-05, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 7.46737659732104e-05, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.027601499524214285}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:10:09,317] Trial 51 finished with value: 0.7961299305687375 and parameters: {'eta': 1.1664384590583796e-07, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.043123067964976315, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.42558182401304084}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:11:01,708] Trial 52 finished with value: 0.7897544079294805 and parameters: {'eta': 1.1834666108380631e-07, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.13163369491702892, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.0972339622570232}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:13:02,201] Trial 53 finished with value: 0.8158581383189609 and parameters: {'eta': 2.8265662448416405e-08, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.13666256641809843, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.3643358512549616}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:14:36,434] Trial 54 finished with value: 0.7411950457395815 and parameters: {'eta': 2.247194687457664e-08, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.009748994481253192, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.427993513593356}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:17:17,864] Trial 55 finished with value: 0.8050582682641834 and parameters: {'eta': 5.860601968101238e-07, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.05808786467183798, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.6550932490914179}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:19:03,367] Trial 56 finished with value: 0.8023114100009734 and parameters: {'eta': 2.8162070598742364e-06, 'max_depth': 9, 'min_child_weight': 0, 'subsample': 0.04357132894944607, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.4000109813826404}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:21:42,832] Trial 57 finished with value: 0.8051299922880926 and parameters: {'eta': 2.6543415773291207e-06, 'max_depth': 8, 'min_child_weight': 0, 'subsample': 0.05174950881684383, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.7516141371985001}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:23:58,680] Trial 58 finished with value: 0.7632039178639077 and parameters: {'eta': 2.159960126018943e-06, 'max_depth': 8, 'min_child_weight': 0, 'subsample': 0.009335944958233922, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.6892741812124745}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:25:01,922] Trial 59 finished with value: 0.5053687226274792 and parameters: {'eta': 0.0001134803259136271, 'max_depth': 5, 'min_child_weight': 0, 'subsample': 0.00017691598931724524, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.9669755029777599}. Best is trial 20 with value: 0.8243185438593988.\n",
      "[I 2020-08-20 21:25:24,769] Trial 60 finished with value: 0.43802199010450715 and parameters: {'eta': 7.833936973319734e-06, 'max_depth': 10, 'min_child_weight': 0, 'subsample': 0.0015421256034597497, 'sampling_method': 'gradient_based', 'colsample_bytree': 9.578341830514253e-06}. Best is trial 20 with value: 0.8243185438593988.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-cd3a3e415c4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#xgb_study2 = optuna.create_study(direction='maximize')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxgb_study2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_hyperparam2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 self._optimize_sequential(\n\u001b[1;32m--> 292\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m                 )\n\u001b[0;32m    294\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    652\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;31m# type: (...) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-a7d3bfc99544>\u001b[0m in \u001b[0;36mfind_hyperparam2\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     22\u001b[0m                              )\n\u001b[0;32m     23\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgbc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'balanced_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 248\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#xgb_study2 = optuna.create_study(direction='maximize')\n",
    "xgb_study2.optimize(find_hyperparam2, timeout = 60*60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving study\n",
    "#mod = open('PKL/xgb_study2.pkl', 'wb')\n",
    "#pickle.dump(xgb_study2, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the study\n",
    "#xgb_study2 = pickle.load(open('PKL/xgb_study2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.779 / Test Accuracy:  0.687\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.80      0.84      0.82      4822\n",
      "functional needs repair       0.41      0.47      0.44       678\n",
      "         non functional       0.83      0.75      0.79      3410\n",
      "\n",
      "               accuracy                           0.78      8910\n",
      "              macro avg       0.68      0.69      0.68      8910\n",
      "           weighted avg       0.78      0.78      0.78      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbc2 = xgb.XGBClassifier(**xgb_study2.best_params, n_jobs= -1, verbosity=1)\n",
    "xgbc2.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = xgbc2.predict(X_test_ohe)    \n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['XGB_opt_2'] = (f1_test, acc_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is definitely an improvement with the minority class prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/xgbc_model_smote.pkl', 'wb')\n",
    "#pickle.dump(xgbc2, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna.visualization.plot_optimization_history(xgb_study)\n",
    "#optuna.visualization.plot_optimization_history(xgb_study2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "Now I will try to run a voting classifier using the above methods.Since only random forest did well in predicting minority class without oversampling. I will use oversampled data for voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = xgb.XGBClassifier(colsample_bytree=0.8626151873679676, eta=0.001038709382469881,\n",
    "              max_depth=15, objective='multi:softprob',\n",
    "              sampling_method='gradient_based', subsample=0.6665960477032411)\n",
    "xgbc2 = xgb.XGBClassifier(colsample_bytree=0.996, eta=1.0035409883128274e-05,\n",
    "              max_delta_step=1, max_depth=9, min_child_weight=0,\n",
    "              num_parallel_tree=7, objective='multi:softprob',\n",
    "              sampling_method='uniform', subsample=0.0723008974366997)\n",
    "rf = RandomForestClassifier(class_weight='balanced_subsample', max_depth=10, max_features=34, n_estimators=365, oob_score=True)\n",
    "knc_opt = KNeighborsClassifier(algorithm='ball_tree', leaf_size=49, n_neighbors=4, p=1, weights='distance')\n",
    "knc_g = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "dtcSimple = DecisionTreeClassifier(class_weight='balanced', max_depth=20)\n",
    "knnOptuna = KNeighborsClassifier(algorithm='kd_tree', leaf_size=6, n_neighbors=2, p=1)\n",
    "knnSimple = KNeighborsClassifier()\n",
    "rfc_Optuna = RandomForestClassifier(class_weight='balanced', max_depth=10, max_features=0.066, n_estimators=572)\n",
    "rfcSimple = RandomForestClassifier(class_weight='balanced_subsample', max_depth=3, max_features=0.3, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing\n",
    "X_train_scaled = scale.fit_transform(X_train_res)\n",
    "X_test_scaled = scale.transform(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunjoo\\anaconda3\\lib\\site-packages\\joblib\\disk.py:122: UserWarning: Unable to delete folder C:\\Users\\Eunjoo\\AppData\\Local\\Temp\\joblib_memmapping_folder_13352_5453397899 after 5 tentatives.\n",
      "  .format(folder_path, RM_SUBDIRS_N_RETRY))\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\Eunjoo\\\\AppData\\\\Local\\\\Temp\\\\joblib_memmapping_folder_13352_5453397899\\\\13352-2747511024584-06f2885557d548f6bd53e6e4402da8ea.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-11d3148b1e1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                             \u001b[0mvoting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'soft'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                            n_jobs = -1, verbose = True)\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mvoting_c_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     79\u001b[0m                                                   idx + 1, len(clfs))\n\u001b[0;32m     80\u001b[0m                 )\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             )\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1025\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pickle_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_terminate_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;31m# in latter calls but we free as much memory as we can by deleting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[1;31m# the shared memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[0mdelete_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\disk.py\u001b[0m in \u001b[0;36mdelete_folder\u001b[1;34m(folder_path, onerror)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWindowsError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[1;31m# can't continue even if onerror hook returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    398\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\Eunjoo\\\\AppData\\\\Local\\\\Temp\\\\joblib_memmapping_folder_13352_5453397899\\\\13352-2747511024584-06f2885557d548f6bd53e6e4402da8ea.pkl'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_c_all = VotingClassifier(estimators = [('xgbc', xgbc), \n",
    "                                          ('xgbc2', xgbc2), \n",
    "                                          ('rf', rf),\n",
    "                                          ('knc_opt', knc_opt),\n",
    "                                          ('knc_g', knc_g),\n",
    "                                          ('dtcSimple', dtcSimple),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('knnSimple', knnSimple),\n",
    "                                          ('rfc_Optuna', rfc_Optuna),\n",
    "                                          ('rfcSimple', rfcSimple),\n",
    "                                         ], \n",
    "                            voting = 'soft', \n",
    "                           n_jobs = -1, verbose = True)\n",
    "voting_c_all.fit(X_train_scaled, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_c_all.predict(X_test_scaled)    \n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['voting_equal_soft'] = (f1_test, acc_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/voting_equal.pkl', 'wb')\n",
    "pickle.dump(voting_c, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.765 / Test Accuracy:  0.677\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.80      0.81      4822\n",
      "functional needs repair       0.37      0.47      0.41       678\n",
      "         non functional       0.79      0.76      0.78      3410\n",
      "\n",
      "               accuracy                           0.76      8910\n",
      "              macro avg       0.66      0.68      0.67      8910\n",
      "           weighted avg       0.77      0.76      0.77      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_c.predict(X_test_ohe)    \n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['voting_equal_soft'] = (f1_test, acc_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLasso = LogisticRegression(penalty = 'l1', \n",
    "                                 tol = 0.0001, \n",
    "                                 C = 1, \n",
    "                                 solver='liblinear', \n",
    "                                 class_weight = 'balanced', \n",
    "                                 max_iter = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_test, y_pred):\n",
    "    f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "    acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "    print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.736 / Test Accuracy:  0.62\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.77      0.82      0.79      4822\n",
      "functional needs repair       0.31      0.35      0.33       678\n",
      "         non functional       0.78      0.69      0.73      3410\n",
      "\n",
      "               accuracy                           0.73      8910\n",
      "              macro avg       0.62      0.62      0.62      8910\n",
      "           weighted avg       0.74      0.73      0.74      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LogRegLasso.fit(X_train_scaled, y_train_res)\n",
    "#y_pred_lasso = LogRegLasso.predict(X_test_scaled)\n",
    "scoring(y_test, y_pred_lasso)\n",
    "print(classification_report(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "mod = open('PKL/LogRegLasso.pkl', 'wb')\n",
    "pickle.dump(LogRegLasso, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
