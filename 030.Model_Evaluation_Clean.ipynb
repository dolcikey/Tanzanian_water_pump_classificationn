{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "In this notebook, we will test multiple model and evaluate to choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "X = pd.read_pickle('PKL/X_train.pkl')\n",
    "y = pd.read_pickle('PKL/Y_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "We will split the train data once more. It's because this is a competition dataset and we actually don't have the 'test' score result. So we will use the test set we created from the initial training set as a holdout set to actually see our performance of the final model. The final test set, which we don't have the labels for, will be used to make a prediction in the final testing notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 13, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We will be utilizing mostly KNN and tree-based algorithms. We will first turn categorical features to binary dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning all categorical features to dummies \n",
    "X_train_ohe = pd.get_dummies(X_train)\n",
    "X_test_ohe = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "# Check if training and testing sets have the same features\n",
    "if X_train_ohe.shape[1] != X_test_ohe.shape[1]:\n",
    "    print([x for x in X_train_ohe.columns if x not in X_test_ohe.columns])\n",
    "    print([x for x in X_test_ohe.columns if x not in X_train_ohe.columns])\n",
    "else: \n",
    "    print ('Good to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If they are not the same, add the column with 0s and fix the order\n",
    "# X_test_ohe[colname] = 0\n",
    "# X_test_ohe = X_test_ohe[X_train_ohe.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance Issue\n",
    "Our dataset has high class imbalance issue. We will mostly deal with this by setting the class weight within each model, but in some cases where imbalance weight is not adequately dealt with by algorithm we test with resampled set using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_res, y_train_res = smote.fit_sample(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Our target is multi-class with imbalance issue. To focus on the imbalance of minority classes, we will use balanced accuracy score as our primary metrics. This computes the average accuracy score weighted by the inverse prevalence of the true classes. Additionally we will also look at the weighted f1 score to capture the predictive performance for overall classes. It calculates the f1 score for each class and find the average weighted by the number of actual positive cases in each class, so naturally penalizes if minority recall is low.\n",
    "\n",
    "In terms of prediction of each class, we rather want to overpredict 'needs repair'(minority) case than the functional cases. Because the consistent health of the well is crucial for survival of surrounding population. Specifically, we want the sensitivy of the repair cases to be high because false positive of minority classes is better than missing those actually needing repairs. I will look at this breakdown using the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score, plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier\n",
    "We'll first create a dummy classifier as a baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.444 / Test Accuracy:  0.336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummyc = DummyClassifier(strategy = 'stratified') # using the default stratified strategy\n",
    "dummyc.fit(X_train_ohe, y_train)\n",
    "y_pred = dummyc.predict(X_test_ohe)\n",
    "\n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "score_keeper['baseline'] = (f1_test, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.54      0.53      0.54      4822\n",
      "functional needs repair       0.09      0.08      0.08       678\n",
      "         non functional       0.38      0.39      0.39      3410\n",
      "\n",
      "               accuracy                           0.44      8910\n",
      "              macro avg       0.34      0.34      0.34      8910\n",
      "           weighted avg       0.44      0.44      0.44      8910\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(dummyc, X_test_ohe, y_test, xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stratified dummy classifier shows the weighted F1 score around .45 and less balanced accuracy. Dummy classifier is consistently wrong on all cases but recall for minority classes are especially bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNearestNeighbors\n",
    "Now we will run K-Nearest Neighbors using GridSearchCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "For kNN, all feature values need to be standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train_scaled = scale.fit_transform(X_train_ohe)\n",
    "X_test_scaled = scale.transform(X_test_ohe)\n",
    "\n",
    "X_train_res_scaled = scale.fit_transform(X_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Function\n",
    "Function to return weighted F1 and balanced accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_test, y_pred):\n",
    "    f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "    acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "    print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal value for K using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_neighbors': range(1, 16, 2), # setting K\n",
    "}\n",
    "\n",
    "knc = KNeighborsClassifier(weights = 'distance') \n",
    "knc_g = GridSearchCV(knc, params, cv = 5, scoring = 'balanced_accuracy', verbose = 1, n_jobs = -1)\n",
    "knc_g.fit(X_train_scaled, y_train)\n",
    "#print(knc_g.best_params_, ': ', knc_g.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN performance on the test set\n",
    "y_pred = knc_g.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.741 / Test Accuracy:  0.622\n",
    "# Recall for functional needs repair: 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = knc_g.predict(X_train_scaled)    \n",
    "f1_test = round(f1_score(y_train, y_train_pred, average = 'weighted'), 3)\n",
    "f1_test\n",
    "# 0.998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall improvement from the dummy model, but the recall of needs repair class is still low. Looking at training score (.99) shows that it's highly overfitting. In this document we'll see if different optimization method finds a better hyperparameter.  \n",
    "\n",
    "*Future consideration - In 030B file under eunjoo branch, we explored more into limiting features using random forest feature selection for KNN as KNN does not select features and can make the model messy. As a summary, after Random Forest feature selection, the performance didn't improve, but also didn't drop. So we know for KNN those extra features could be unnecessarily complicating our model. For the sake of keeping it consistent with the rest of models, we will keep all features (they have been already selected based on intuition in the EDA notebook) for now. But we may consider dropping some of those features in the future.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model \n",
    "#mod = open('PKL/knn_gsc.pkl', 'wb')\n",
    "#pickle.dump(knc_g.best_estimator_, mod)\n",
    "#mod.close()\n",
    "# Reload the model\n",
    "#knc_g = pickle.load(open('PKL/knn_gsc.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with Optuna\n",
    "Now we want to try different optimization method to make sure we have the best hyperparmeter for KNN. This time we'll use optuna to explore even more hyperparameters. We'll cap the time to what it took to be same as the time it took to complete GridSearch above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hyperp_KNN(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 31)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    leaf_size = trial.suggest_int('leaf_size', 2, 60)\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "    knc = KNeighborsClassifier(weights = 'distance', \n",
    "                             n_neighbors = n_neighbors, \n",
    "                             algorithm = algorithm, \n",
    "                             leaf_size = leaf_size, \n",
    "                             p = p)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(knc, X_train_scaled, y_train, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "# initiating the optuna study\n",
    "knn_study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# optimization process\n",
    "knn_study.optimize(find_hyperp_KNN, timeout = 16*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the study \n",
    "#mod = open('PKL/knn_study.pkl', 'wb')\n",
    "#pickle.dump(knn_study, mod)\n",
    "#mod.close()\n",
    "# Reload the study\n",
    "#knn_study = pickle.load(open('PKL/knn_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the best params on the test set\n",
    "knc_opt = KNeighborsClassifier(**knn_study.best_params, weights = 'distance')\n",
    "knc_opt.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knc_opt.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.753 / Test Accuracy:  0.631\n",
    "# functional needs repair recall = 0.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score for the needs repair class is still low but the overall performance and the recall for non-functional improved slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "#mod = open('PKL/knc_opt_model.pkl', 'wb')\n",
    "#pickle.dump(knc_opt, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE - kNN \n",
    "Since kNN consistently failed to improve recall score for the minority class, we'll try to run it with SMOTE resampled set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple kNN\n",
    "Running kNN with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnSimple = KNeighborsClassifier()\n",
    "knnSimple.fit(X_train_res_scaled, y_train)\n",
    "y_pred = knnSimple.predict(X_test_res_scaled)\n",
    "\n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.717 / Test Accuracy:  0.656\n",
    "# needs repair recall = 0.54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minority recall score has improved! let's try to optimize hyperparmeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod = open('PKL/knnSimple.pkl', 'wb')\n",
    "#pickle.dump(knnSimple, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_objective(trial): \n",
    "    knn_neighbors = trial.suggest_int('n_neighbors', 1,10) \n",
    "    knn_p = trial.suggest_categorical('p', [1, 2])\n",
    "    knn_leaf_size = trial.suggest_int('leaf_size', 2, 50)\n",
    "    knn_algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = knn_neighbors, \n",
    "                               p = knn_p, \n",
    "                               leaf_size = knn_leaf_size,\n",
    "                               algorithm =  knn_algorithm)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(knc, X_train_res_scaled, y_train_res, scoring = 'balanced_accuracy', \n",
    "                                    cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "# initiating the optuna study\n",
    "knn_optuna = optuna.create_study(direction='maximize')\n",
    "\n",
    "# optimization process\n",
    "knn_optuna.optimize(knn_objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the best params on the test set\n",
    "knnOptuna = KNeighborsClassifier(**knn_optuna.best_params)\n",
    "knnOptuna.fit(X_train_res_scaled, y_train_res)\n",
    "\n",
    "y_pred = knnOptuna.predict(X_test_res_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Test F1 score:  0.742 / Test Accuracy:  0.567\n",
    "# functional needs repair recall = 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna hyperparameter did not improved our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/knnOptuna.pkl', 'wb')\n",
    "#pickle.dump(knnOptuna, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Decision Trees\n",
    "Since we have a lot of features, tree-based model might deal better by ignoring less important features. We will first try with a simple tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcSimple = DecisionTreeClassifier(criterion = 'gini', \n",
    "                                   max_depth = 20, \n",
    "                                   class_weight = 'balanced')\n",
    "dtcSimple.fit(X_train_res_scaled, y_train)\n",
    "y_pred_dtcSimple = dtcSimple.predict(X_test_res_scaled)\n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.728 / Test Accuracy:  0.642\n",
    "# functional needs repair recall = 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About similar performance as kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "We will run random forest optimized by Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparam_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 700)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    #min_samples_split = trial.suggest_int('min_samples_split', 0, 10)\n",
    "    #min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 15)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    class_weight = trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\n",
    "    max_features = trial.suggest_int('max_features', 2, 100)\n",
    "    rfc = RandomForestClassifier(oob_score = True, \n",
    "                             n_estimators = n_estimators, \n",
    "                             max_depth = max_depth, \n",
    "                             #min_samples_split = min_samples_split, \n",
    "                             #min_samples_leaf = min_samples_leaf, \n",
    "                             criterion = criterion, \n",
    "                             class_weight = class_weight, \n",
    "                             max_features = max_features)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(rfc, X_train_ohe, y_train, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "#rfc_study = optuna.create_study(direction='maximize')\n",
    "rfc_study.optimize(find_hyperparam_rf, timeout = 60*60*3) # run it for 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(oob_score = True, **rfc_study.best_params)\n",
    "\n",
    "rf.fit(X_train_ohe, y_train)\n",
    "y_pred = rf.predict(X_test_ohe)  \n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.731 / Test Accuracy:  0.694\n",
    "# functional needs repair recall = 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better performance in predicting the positive minority cases even though overall F1 score has dropped slightly. This model seems to be weighing the minority recall better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the study\n",
    "#mod = open('PKL/rfc_study.pkl', 'wb')\n",
    "#pickle.dump(rfc_study, mod)\n",
    "#mod.close()\n",
    "# Reload the study\n",
    "#rfc_study = pickle.load(open('PKL/rfc_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "#mod = open('PKL/rf_model.pkl', 'wb')\n",
    "#pickle.dump(rf, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "Now we'll try to run XGBoost with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparam(trial):\n",
    "    eta = trial.suggest_loguniform('eta', 0.001, 0.5)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 15)\n",
    "    #min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_loguniform('subsample', 0.1, 1.0)\n",
    "    sampling_method = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.1, 1.0)\n",
    "    xgbc = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                             eta = eta, \n",
    "                             num_boost_round = 999, \n",
    "                             early_stopping_rounds=10, \n",
    "                             max_depth = max_depth, \n",
    "                             #min_child_weight = min_child_weight, \n",
    "                             subsample = subsample, \n",
    "                             sampling_method = sampling_method, \n",
    "                             colsample_bytree = colsample_bytree)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train_ohe, y_train, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "xgb_study = optuna.create_study(direction='maximize')\n",
    "xgb_study.optimize(find_hyperparam, timeout = 60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.802 / Test Accuracy:  0.664\n"
     ]
    }
   ],
   "source": [
    "# fitting and testing on the test set\n",
    "\n",
    "xgbc = xgb.XGBClassifier(**xgb_study.best_params, n_jobs= -1, verbosity=1)\n",
    "\n",
    "xgbc.fit(X_train_ohe, y_train)\n",
    "y_pred = xgbc.predict(X_test_ohe)    \n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.802 / Test Accuracy:  0.664\n",
    "# functional needs repair recall = 0.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top majority classes are doing so much better, but the minority class recall score dropped significantly from random forest model. We'll try to oversampling the minority classes and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving study\n",
    "#mod = open('PKL/xgb_study.pkl', 'wb')\n",
    "#pickle.dump(xgb_study, mod)\n",
    "#mod.close()\n",
    "# Reload the study\n",
    "#xgb_study = pickle.load(open('PKL/xgb_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/xgbc_model.pkl', 'wb')\n",
    "#pickle.dump(xgbc, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE - XGBoost\n",
    "In order to control for class imbalance in XGBoost, we'll use SMOTE resampled set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna optimization\n",
    "def find_hyperparam2(trial):\n",
    "    \n",
    "    eta = trial.suggest_loguniform(\"eta\", 1e-8, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_loguniform(\"subsample\", 1e-8, 1.0)\n",
    "    sampling_method = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    colsample_bytree = trial.suggest_loguniform(\"colsample_bytree\", 1e-8, 1.0)\n",
    "    num_parallel_tree = trial.suggest_int('num_parallel_tree', 1, 10)\n",
    "    max_delta_step = trial.suggest_int('max_delta_step', 0, 1)\n",
    "    xgbc = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                             eta = eta, \n",
    "                             num_boost_round = 999, \n",
    "                             early_stopping_rounds=10, \n",
    "                             max_depth = max_depth, \n",
    "                             min_child_weight = min_child_weight, \n",
    "                             subsample = subsample, \n",
    "                             sampling_method = sampling_method, \n",
    "                             colsample_bytree = colsample_bytree, \n",
    "                             num_parallel_tree = num_parallel_tree, \n",
    "                             max_delta_step = max_delta_step,\n",
    "                             )\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train_res, y_train_res, \n",
    "                                    scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "xgb_study2 = optuna.create_study(direction='maximize')\n",
    "xgb_study2.optimize(find_hyperparam2, timeout = 60*60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc2 = xgb.XGBClassifier(**xgb_study2.best_params, n_jobs= -1, verbosity=1)\n",
    "xgbc2.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = xgbc2.predict(X_test_ohe)    \n",
    "scoring(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Test F1 score:  0.779 / Test Accuracy:  0.687\n",
    "# functional needs repair recall = 0.47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is definitely an improvement with the minority class prediction compared to XGBoost on the imbalance set. If we have time, we should consider continue running this for further optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving study\n",
    "#mod = open('PKL/xgb_study2.pkl', 'wb')\n",
    "#pickle.dump(xgb_study2, mod)\n",
    "#mod.close()\n",
    "# Reload the study\n",
    "#xgb_study2 = pickle.load(open('PKL/xgb_study2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/xgbc_model_smote.pkl', 'wb')\n",
    "#pickle.dump(xgbc2, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "Now I will try to run a voting classifier using some of the above models. Since many of the models did better with with minority classes oversampled, I will use oversampled data for voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_c_all = VotingClassifier(estimators = [('xgbc', xgbc), \n",
    "                                          ('xgbc2', xgbc2), \n",
    "                                          ('rf', rf),\n",
    "                                          ('knc_opt', knc_opt),\n",
    "                                          ('knc_g', knc_g),\n",
    "                                          ('dtcSimple', dtcSimple),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('knnSimple', knnSimple),\n",
    "                                          ('rfc_Optuna', rfc_Optuna),\n",
    "                                          ('rfcSimple', rfcSimple),\n",
    "                                         ], \n",
    "                            voting = 'soft', \n",
    "                           n_jobs = -1)\n",
    "voting_c_all.fit(X_train_res_scaled, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_c_all.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.77 / Test Accuracy:  0.671\n",
    "# functional needs repair recall = 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall performance did not improve compare to random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#mod = open('PKL/voting_equal_full.pkl', 'wb')\n",
    "#pickle.dump(voting_c_all, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "#voting_c_all = pickle.load(open('PKL/voting_equal_full.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Lasso Regularization\n",
    "We will look at running logistic regression with lasso penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLasso = LogisticRegression(penalty = 'l1', \n",
    "                                 tol = 0.0001, \n",
    "                                 C = 1, \n",
    "                                 solver='liblinear', \n",
    "                                 class_weight = 'balanced', \n",
    "                                 max_iter = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLasso.fit(X_train_res_scaled, y_train_res)\n",
    "y_pred_lasso = LogRegLasso.predict(X_test_scaled)\n",
    "scoring(y_test, y_pred_lasso)\n",
    "print(classification_report(y_test, y_pred_lasso))\n",
    "# Test F1 score:  0.68 / Test Accuracy:  0.695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar performance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/LogRegLasso.pkl', 'wb')\n",
    "#pickle.dump(LogRegLasso, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting 2 with Logistic Regression\n",
    "We will run the hard vote with logistic regression included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_c_all2 = VotingClassifier(estimators = [('xgbc', xgbc), \n",
    "                                          ('xgbc2', xgbc2), \n",
    "                                          ('rf', rf),\n",
    "                                          ('knc_opt', knc_opt),\n",
    "                                          ('knc_g', knc_g),\n",
    "                                          ('dtcSimple', dtcSimple),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('knnSimple', knnSimple),\n",
    "                                          ('rfc_Optuna', rfc_Optuna),\n",
    "                                          ('rfcSimple', rfcSimple),\n",
    "                                          ('LogRegLasso', LogRegLasso),\n",
    "                                         ], \n",
    "                            voting = 'hard', \n",
    "                           n_jobs = -1)\n",
    "voting_c_all2.fit(X_train_res_scaled, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_c_all2.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.77 / Test Accuracy:  0.682\n",
    "# functional needs repair = 0.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improved the minority class performance slightly than previous voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod = open('PKL/voting_equal_full2.pkl', 'wb')\n",
    "#pickle.dump(voting_c_all2, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting 3 with Select Model\n",
    "We will run the hard vote with different set of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_c_all3 = VotingClassifier(estimators = [('LogRegLasso', LogRegLasso), \n",
    "                                          ('LogReg', LogReg), \n",
    "                                          ('knn', knn),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('rfc_Optuna', rfc_Optuna),\n",
    "                                          ('rfc_Optuna2', rfc_Optuna2),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('knnSimple', knnSimple),\n",
    "                                          ('rfc_Optuna', rfc_Optuna),\n",
    "                                          ('rfcSimple', rfcSimple),\n",
    "                                         ], \n",
    "                            voting = 'hard', \n",
    "                           n_jobs = -1)\n",
    "voting_c_all3.fit(X_train_res_scaled, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_c_all3.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.758 / Test Accuracy:  0.708\n",
    "# functional needs repair = 0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall better performance. We will choose between the random forest and this voting classifier for the final model. (If time, we should include the random forest and run weighted voting to improve this model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
