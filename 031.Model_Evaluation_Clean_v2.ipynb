{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "In this notebook, we will test multiple model and evaluate to choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "X = pd.read_pickle('PKL/X_train.pkl')\n",
    "y = pd.read_pickle('PKL/Y_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "We will split the train data once more. It's because this is a competition dataset and we actually don't have the 'test' score result. So we will use the test set we created from the initial training set as a holdout set to actually see our performance of the final model. The final test set, which we don't have the labels for, will be used to make a prediction in the final testing notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 13, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We will be utilizing mostly KNN and tree-based algorithms. We will first turn categorical features to binary dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning all categorical features to dummies \n",
    "X_train_ohe = pd.get_dummies(X_train)\n",
    "X_test_ohe = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "# Check if training and testing sets have the same features\n",
    "if X_train_ohe.shape[1] != X_test_ohe.shape[1]:\n",
    "    print([x for x in X_train_ohe.columns if x not in X_test_ohe.columns])\n",
    "    print([x for x in X_test_ohe.columns if x not in X_train_ohe.columns])\n",
    "else: \n",
    "    print ('Good to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If they are not the same, add the column with 0s and fix the order\n",
    "# X_test_ohe[colname] = 0\n",
    "# X_test_ohe = X_test_ohe[X_train_ohe.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance Issue\n",
    "Our dataset has high class imbalance issue. We will mostly deal with this by setting the class weight within each model, but in some cases where imbalance weight is not adequately dealt with by algorithm we test with resampled set using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_res, y_train_res = smote.fit_sample(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Our target is multi-class with imbalance issue. To focus on the imbalance of minority classes, we will use balanced accuracy score as our primary metrics. This computes the average accuracy score weighted by the inverse prevalence of the true classes (both positive and negative). So it accounts for the imbalance more rigorously then the weighted f1 score, which only takes the number of positive cases into account. Additionally we will also look at the weighted f1 score to capture the predictive performance for overall classes. It calculates the f1 score for each class and find the average weighted by the number of actual positive cases in each class, so naturally penalizes if minority recall is low.\n",
    "\n",
    "In terms of prediction within each class, we rather want to overpredict 'needs repair'(minority) or 'non functional' cases  than the functional cases. Because the condition of the well is crucial for survival of surrounding population. Specifically, we want the recall of the non functional and needs repair cases to be high because false positive of minority classes is better than missing those actually needing repairs. I will look at this breakdown using the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score, plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier\n",
    "We'll first create a dummy classifier as a baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.446 / Test Accuracy:  0.337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummyc = DummyClassifier(strategy = 'stratified') # using the default stratified strategy\n",
    "dummyc.fit(X_train_ohe, y_train)\n",
    "y_pred = dummyc.predict(X_test_ohe)\n",
    "\n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.54      0.54      0.54      4822\n",
      "functional needs repair       0.09      0.08      0.08       678\n",
      "         non functional       0.38      0.39      0.38      3410\n",
      "\n",
      "               accuracy                           0.45      8910\n",
      "              macro avg       0.34      0.34      0.34      8910\n",
      "           weighted avg       0.45      0.45      0.45      8910\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(dummyc, X_test_ohe, y_test, xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stratified dummy classifier shows the weighted F1 score around .45 and less balanced accuracy. Dummy classifier is consistently wrong on all cases but recall for minority classes are especially bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNearestNeighbors\n",
    "Now we will run K-Nearest Neighbors using GridSearchCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "For kNN, all feature values need to be standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train_scaled = scale.fit_transform(X_train_ohe)\n",
    "X_test_scaled = scale.transform(X_test_ohe)\n",
    "\n",
    "X_train_res_scaled = scale.fit_transform(X_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Function\n",
    "Function to return weighted F1 and balanced accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_test, y_pred):\n",
    "    f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "    acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "    print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal value for K using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 15.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(weights='distance'),\n",
       "             n_jobs=-1, param_grid={'n_neighbors': range(1, 16, 2)},\n",
       "             scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': range(1, 16, 2), # setting K\n",
    "}\n",
    "\n",
    "knc = KNeighborsClassifier(weights = 'distance') \n",
    "knc_g = GridSearchCV(knc, params, cv = 5, scoring = 'balanced_accuracy', verbose = 1, n_jobs = -1)\n",
    "knc_g.fit(X_train_scaled, y_train)\n",
    "#print(knc_g.best_params_, ': ', knc_g.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.741 / Test Accuracy:  0.622\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.78      0.81      0.79      4822\n",
      "functional needs repair       0.39      0.32      0.35       678\n",
      "         non functional       0.75      0.74      0.74      3410\n",
      "\n",
      "               accuracy                           0.74      8910\n",
      "              macro avg       0.64      0.62      0.63      8910\n",
      "           weighted avg       0.74      0.74      0.74      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN performance on the test set\n",
    "y_pred = knc_g.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.741 / Test Accuracy:  0.622\n",
    "# Recall for functional needs repair: 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = knc_g.predict(X_train_scaled)    \n",
    "f1_test = round(f1_score(y_train, y_train_pred, average = 'weighted'), 3)\n",
    "f1_test\n",
    "# 0.998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall improvement from the dummy model, but the recall of needs repair class is still low. Looking at training score (.99) shows that it's highly overfitting. In this document we'll see if different optimization method finds a better hyperparameter.  \n",
    "\n",
    "*Future consideration - In 030B file under eunjoo branch, we explored more into limiting features using random forest feature selection for KNN as KNN does not select features and can make the model messy. As a summary, after Random Forest feature selection, the performance didn't improve, but also didn't drop. So we know for KNN those extra features could be unnecessarily complicating our model. For the sake of keeping it consistent with the rest of models, we will keep all features (they have been already selected based on intuition in the EDA notebook) for now. But we may consider dropping some of those features in the future.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model \n",
    "#mod = open('PKL/knn_gsc.pkl', 'wb')\n",
    "#pickle.dump(knc_g.best_estimator_, mod)\n",
    "#mod.close()\n",
    "# Reload the model\n",
    "#knc_g = pickle.load(open('PKL/knn_gsc.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with Optuna\n",
    "Now we want to try different optimization method to make sure we have the best hyperparmeter for KNN. This time we'll use optuna to explore even more hyperparameters. We'll cap the time to what it took to be same as the time it took to complete GridSearch above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-23 14:12:56,309] Trial 0 finished with value: 0.6241109524591881 and parameters: {'n_neighbors': 21, 'algorithm': 'kd_tree', 'leaf_size': 8, 'p': 1}. Best is trial 0 with value: 0.6241109524591881.\n",
      "[I 2020-08-23 14:17:03,858] Trial 1 finished with value: 0.6138424591785228 and parameters: {'n_neighbors': 13, 'algorithm': 'ball_tree', 'leaf_size': 57, 'p': 2}. Best is trial 0 with value: 0.6241109524591881.\n",
      "[I 2020-08-23 14:20:47,069] Trial 2 finished with value: 0.6212834696398344 and parameters: {'n_neighbors': 26, 'algorithm': 'kd_tree', 'leaf_size': 48, 'p': 1}. Best is trial 0 with value: 0.6241109524591881.\n",
      "[I 2020-08-23 14:25:02,426] Trial 3 finished with value: 0.6242868465865195 and parameters: {'n_neighbors': 20, 'algorithm': 'ball_tree', 'leaf_size': 21, 'p': 1}. Best is trial 3 with value: 0.6242868465865195.\n",
      "[I 2020-08-23 14:28:21,393] Trial 4 finished with value: 0.6264078004705633 and parameters: {'n_neighbors': 17, 'algorithm': 'kd_tree', 'leaf_size': 12, 'p': 1}. Best is trial 4 with value: 0.6264078004705633.\n"
     ]
    }
   ],
   "source": [
    "def find_hyperp_KNN(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 31)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    leaf_size = trial.suggest_int('leaf_size', 2, 60)\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "    knc = KNeighborsClassifier(weights = 'distance', \n",
    "                             n_neighbors = n_neighbors, \n",
    "                             algorithm = algorithm, \n",
    "                             leaf_size = leaf_size, \n",
    "                             p = p)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(knc, X_train_scaled, y_train, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "# initiating the optuna study\n",
    "knn_study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# optimization process\n",
    "knn_study.optimize(find_hyperp_KNN, timeout = 16*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the study \n",
    "#mod = open('PKL/knn_study.pkl', 'wb')\n",
    "#pickle.dump(knn_study, mod)\n",
    "#mod.close()\n",
    "# Reload the study\n",
    "#knn_study = pickle.load(open('PKL/knn_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.759 / Test Accuracy:  0.63\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.78      0.85      0.81      4822\n",
      "functional needs repair       0.47      0.30      0.37       678\n",
      "         non functional       0.78      0.74      0.76      3410\n",
      "\n",
      "               accuracy                           0.77      8910\n",
      "              macro avg       0.68      0.63      0.65      8910\n",
      "           weighted avg       0.76      0.77      0.76      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the best params on the test set\n",
    "knc_opt = KNeighborsClassifier(**knn_study.best_params, weights = 'distance')\n",
    "knc_opt.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knc_opt.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.753 / Test Accuracy:  0.631\n",
    "# functional needs repair recall = 0.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score for the needs repair class is still low but the overall performance and the recall for non-functional improved slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "#mod = open('PKL/knc_opt_model.pkl', 'wb')\n",
    "#pickle.dump(knc_opt, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knc_study = pickle.load(open('PKL/knc_opt_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE - kNN \n",
    "Since kNN consistently failed to improve recall score for the minority class, we'll try to run it with SMOTE resampled set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple kNN\n",
    "Running kNN with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.719 / Test Accuracy:  0.625\n"
     ]
    }
   ],
   "source": [
    "knnSimple = KNeighborsClassifier(n_jobs = -1)\n",
    "knnSimple.fit(X_train_res_scaled, y_train_res)\n",
    "y_pred = knnSimple.predict(X_test_scaled)\n",
    "\n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.717 / Test Accuracy:  0.656\n",
    "# needs repair recall = 0.54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minority recall score has improved! let's try to optimize hyperparmeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod = open('PKL/knnSimple.pkl', 'wb')\n",
    "#pickle.dump(knnSimple, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knnSimple = pickle.load(open('PKL/knnSimple.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-23 14:59:48,105] Trial 0 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 6, 'p': 1, 'leaf_size': 25, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:04:55,104] Trial 1 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 9, 'p': 2, 'leaf_size': 11, 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:10:04,354] Trial 2 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 1, 'p': 1, 'leaf_size': 18, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:15:10,416] Trial 3 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 5, 'p': 2, 'leaf_size': 36, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:20:16,558] Trial 4 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 8, 'p': 1, 'leaf_size': 26, 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:25:23,310] Trial 5 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 6, 'p': 2, 'leaf_size': 35, 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:30:29,381] Trial 6 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 10, 'p': 2, 'leaf_size': 7, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:35:33,038] Trial 7 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 8, 'p': 1, 'leaf_size': 3, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:40:38,126] Trial 8 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 5, 'p': 2, 'leaf_size': 49, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:45:48,417] Trial 9 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 6, 'p': 1, 'leaf_size': 18, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:50:52,833] Trial 10 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 2, 'p': 1, 'leaf_size': 49, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8091345039701233.\n",
      "[I 2020-08-23 15:55:57,594] Trial 11 finished with value: 0.8091345039701233 and parameters: {'n_neighbors': 10, 'p': 2, 'leaf_size': 13, 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.8091345039701233.\n"
     ]
    }
   ],
   "source": [
    "def knn_objective(trial): \n",
    "    knn_neighbors = trial.suggest_int('n_neighbors', 1,10) \n",
    "    knn_p = trial.suggest_categorical('p', [1, 2])\n",
    "    knn_leaf_size = trial.suggest_int('leaf_size', 2, 50)\n",
    "    knn_algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = knn_neighbors, \n",
    "                               p = knn_p, \n",
    "                               leaf_size = knn_leaf_size,\n",
    "                               algorithm =  knn_algorithm)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(knc, X_train_res_scaled, y_train_res, scoring = 'balanced_accuracy', \n",
    "                                    cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "# initiating the optuna study\n",
    "knn_optuna = optuna.create_study(direction='maximize')\n",
    "\n",
    "# optimization process\n",
    "knn_optuna.optimize(knn_objective, n_trials = 100, timeout = 60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.73 / Test Accuracy:  0.635\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.77      0.80      0.79      4822\n",
      "functional needs repair       0.32      0.42      0.37       678\n",
      "         non functional       0.77      0.68      0.72      3410\n",
      "\n",
      "               accuracy                           0.73      8910\n",
      "              macro avg       0.62      0.64      0.63      8910\n",
      "           weighted avg       0.74      0.73      0.73      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the best params on the test set\n",
    "knnOptuna = KNeighborsClassifier(**knn_optuna.best_params)\n",
    "knnOptuna.fit(X_train_res_scaled, y_train_res)\n",
    "\n",
    "y_pred = knnOptuna.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Test F1 score:  0.742 / Test Accuracy:  0.567\n",
    "# functional needs repair recall = 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna hyperparameter did not improved our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/knnOptuna.pkl', 'wb')\n",
    "#pickle.dump(knnOptuna, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knnOptuna = pickle.load(open('PKL/knnOptuna.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Decision Trees\n",
    "Since we have a lot of features, tree-based model might deal better by ignoring less important features. We will first try with a simple tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.73 / Test Accuracy:  0.635\n"
     ]
    }
   ],
   "source": [
    "dtcSimple = DecisionTreeClassifier(criterion = 'gini', \n",
    "                                   max_depth = 20, \n",
    "                                   class_weight = 'balanced')\n",
    "dtcSimple.fit(X_train_res_scaled, y_train_res)\n",
    "y_pred_dtcSimple = dtcSimple.predict(X_test_scaled)\n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.728 / Test Accuracy:  0.642\n",
    "# functional needs repair recall = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/dtcSimple.pkl', 'wb')\n",
    "#pickle.dump(dtcSimple, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtcSimple = pickle.load(open('PKL/dtcSimple.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About similar performance as kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "We will run random forest optimized by Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-23 21:03:03,785] Trial 47 finished with value: 0.7235648411767576 and parameters: {'n_estimators': 653, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 9, 'criterion': 'entropy', 'class_weight': 'balanced', 'max_features': 11}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:06:55,122] Trial 48 finished with value: 0.7312747762280674 and parameters: {'n_estimators': 587, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'max_features': 44}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:07:18,274] Trial 49 finished with value: 0.7128896889037618 and parameters: {'n_estimators': 202, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'max_features': 2}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:08:20,403] Trial 50 finished with value: 0.6331643030226903 and parameters: {'n_estimators': 681, 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'max_features': 16}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:10:05,187] Trial 51 finished with value: 0.6528429758028387 and parameters: {'n_estimators': 599, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'max_features': 25}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:14:20,347] Trial 52 finished with value: 0.7581614079864251 and parameters: {'n_estimators': 644, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'max_features': 37}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:18:24,481] Trial 53 finished with value: 0.745813188278051 and parameters: {'n_estimators': 626, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'max_features': 39}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:23:08,774] Trial 54 finished with value: 0.7571740822345325 and parameters: {'n_estimators': 654, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 8, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'max_features': 42}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:25:38,129] Trial 55 finished with value: 0.7575093590727022 and parameters: {'n_estimators': 560, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'max_features': 20}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:29:36,131] Trial 56 finished with value: 0.7462786813460618 and parameters: {'n_estimators': 506, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'max_features': 50}. Best is trial 21 with value: 0.7646655292923293.\n",
      "[I 2020-08-23 21:31:48,170] Trial 57 finished with value: 0.7581240218025893 and parameters: {'n_estimators': 349, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'max_features': 34}. Best is trial 21 with value: 0.7646655292923293.\n"
     ]
    }
   ],
   "source": [
    "def find_hyperparam_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 700)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    class_weight = trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\n",
    "    max_features = trial.suggest_int('max_features', 2, 100)\n",
    "    min_weight_fraction_leaf = trial.suggest_loguniform('min_weight_fraction_leaf', 0, 0.1),\n",
    "    max_leaf_nodes= trial.suggest_int('max_features', 10, 100)\n",
    "    rfc = RandomForestClassifier(oob_score = True, \n",
    "                             n_estimators = n_estimators, \n",
    "                             max_depth = max_depth, \n",
    "                             min_samples_split = min_samples_split, \n",
    "                             min_samples_leaf = min_samples_leaf, \n",
    "                             criterion = criterion, \n",
    "                             class_weight = class_weight, \n",
    "                             max_features = max_features,\n",
    "                                min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                max_leaf_nodes = max_leaf_nodes)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(rfc, X_train_res_scaled, y_train_res, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "#rfc_study = optuna.create_study(direction='maximize')\n",
    "rfc_study.optimize(find_hyperparam_rf, timeout = 60*30, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(oob_score = True, **rfc_study.best_params)\n",
    "\n",
    "rf.fit(X_train_res_scaled, y_train_res)\n",
    "y_pred = rf.predict(X_test_scaled)  \n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.731 / Test Accuracy:  0.694\n",
    "# functional needs repair recall = 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better performance in predicting the positive minority cases even though overall F1 score has dropped slightly. This model seems to be weighing the minority recall better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the study\n",
    "mod = open('PKL/rfc_study.pkl', 'wb')\n",
    "pickle.dump(rfc_study, mod)\n",
    "mod.close()\n",
    "# Reload the study\n",
    "#rfc_study = pickle.load(open('PKL/rfc_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "#mod = open('PKL/rf_model.pkl', 'wb')\n",
    "#pickle.dump(rf, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_model = pickle.load(open('PKL/rf_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quantity_dry</th>\n",
       "      <td>0.1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_enough</th>\n",
       "      <td>0.0465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_c_other</th>\n",
       "      <td>0.0464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.0373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_other</th>\n",
       "      <td>0.0342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_hand pump</th>\n",
       "      <td>0.0287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga_long</th>\n",
       "      <td>0.0277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction_year</th>\n",
       "      <td>0.0273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>built_recent_after05</th>\n",
       "      <td>0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0.0256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_to_basin</th>\n",
       "      <td>0.0235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga_bariadi</th>\n",
       "      <td>0.0230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>0.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_c_gravity</th>\n",
       "      <td>0.0182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga_lat</th>\n",
       "      <td>0.0179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feat_importance\n",
       "quantity_dry                        0.1169\n",
       "quantity_enough                     0.0465\n",
       "extraction_type_c_other             0.0464\n",
       "longitude                           0.0373\n",
       "waterpoint_type_other               0.0342\n",
       "waterpoint_type_hand pump           0.0287\n",
       "lga_long                            0.0277\n",
       "construction_year                   0.0273\n",
       "built_recent_after05                0.0260\n",
       "latitude                            0.0256\n",
       "dist_to_basin                       0.0235\n",
       "lga_bariadi                         0.0230\n",
       "amount_tsh                          0.0195\n",
       "extraction_type_c_gravity           0.0182\n",
       "lga_lat                             0.0179"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance\n",
    "rf_feats = pd.DataFrame(rf.feature_importances_,\n",
    "                        index = X_train_ohe.columns,\n",
    "                        columns=['feat_importance']).sort_values('feat_importance',ascending=False)\n",
    "rf_feats.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "Now we'll try to run XGBoost with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-23 18:10:44,309] Trial 0 finished with value: 0.8176475208185494 and parameters: {'eta': 0.002066899961526538, 'max_depth': 7, 'subsample': 0.5757376665463694, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.8559395623731328}. Best is trial 0 with value: 0.8176475208185494.\n",
      "[I 2020-08-23 18:14:12,831] Trial 1 finished with value: 0.84227813203974 and parameters: {'eta': 0.002490717467547169, 'max_depth': 12, 'subsample': 0.19339450088588866, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.48641003240449887}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:16:15,528] Trial 2 finished with value: 0.810678631086029 and parameters: {'eta': 0.01422864245439714, 'max_depth': 7, 'subsample': 0.1849934650470781, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.46882892890374533}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:18:02,906] Trial 3 finished with value: 0.8173296341472419 and parameters: {'eta': 0.13350623246783097, 'max_depth': 8, 'subsample': 0.28411525891527084, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.27113649602753986}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:20:19,840] Trial 4 finished with value: 0.8372873613463205 and parameters: {'eta': 0.29374497633634106, 'max_depth': 13, 'subsample': 0.1682047190150505, 'sampling_method': 'uniform', 'colsample_bytree': 0.28417617020039443}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:21:33,277] Trial 5 finished with value: 0.81831934246662 and parameters: {'eta': 0.0024863897845063872, 'max_depth': 11, 'subsample': 0.29584311110088457, 'sampling_method': 'uniform', 'colsample_bytree': 0.11037967207437481}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:25:10,743] Trial 6 finished with value: 0.7887600550845885 and parameters: {'eta': 0.01866101548469517, 'max_depth': 5, 'subsample': 0.5059188877954691, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.7951304273110913}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:28:16,739] Trial 7 finished with value: 0.8394905176591086 and parameters: {'eta': 0.024549161011322856, 'max_depth': 10, 'subsample': 0.4572474074532945, 'sampling_method': 'uniform', 'colsample_bytree': 0.32361606944540566}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:30:32,544] Trial 8 finished with value: 0.8153173607595019 and parameters: {'eta': 0.060919023130184366, 'max_depth': 8, 'subsample': 0.1488911980469914, 'sampling_method': 'uniform', 'colsample_bytree': 0.5064587578320746}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:32:53,004] Trial 9 finished with value: 0.7692424122751602 and parameters: {'eta': 0.2959651222547928, 'max_depth': 4, 'subsample': 0.7282498145638738, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.6650715520082174}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:34:20,155] Trial 10 finished with value: 0.8246500036814608 and parameters: {'eta': 0.0011864002987645782, 'max_depth': 15, 'subsample': 0.10056423833072804, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.15846420204938372}. Best is trial 1 with value: 0.84227813203974.\n",
      "[I 2020-08-23 18:38:02,438] Trial 11 finished with value: 0.8444138633983369 and parameters: {'eta': 0.006722505286512194, 'max_depth': 11, 'subsample': 0.3945165408091133, 'sampling_method': 'uniform', 'colsample_bytree': 0.389373619928488}. Best is trial 11 with value: 0.8444138633983369.\n",
      "[I 2020-08-23 18:42:33,596] Trial 12 finished with value: 0.853001977984348 and parameters: {'eta': 0.0058099241095611875, 'max_depth': 15, 'subsample': 0.24413935159612157, 'sampling_method': 'uniform', 'colsample_bytree': 0.46775978072718827}. Best is trial 12 with value: 0.853001977984348.\n",
      "[I 2020-08-23 18:45:16,242] Trial 13 finished with value: 0.8489784497618071 and parameters: {'eta': 0.006403398275552192, 'max_depth': 15, 'subsample': 0.3681607529884306, 'sampling_method': 'uniform', 'colsample_bytree': 0.20128676924646846}. Best is trial 12 with value: 0.853001977984348.\n",
      "[I 2020-08-23 18:47:25,533] Trial 14 finished with value: 0.8423460069811284 and parameters: {'eta': 0.006196934826236609, 'max_depth': 15, 'subsample': 0.24410404647776981, 'sampling_method': 'uniform', 'colsample_bytree': 0.18983291000579972}. Best is trial 12 with value: 0.853001977984348.\n",
      "[I 2020-08-23 19:05:38,055] Trial 15 finished with value: 0.8558804613805208 and parameters: {'eta': 0.0057790380218066695, 'max_depth': 14, 'subsample': 0.9626562954673942, 'sampling_method': 'uniform', 'colsample_bytree': 0.20036919868049527}. Best is trial 15 with value: 0.8558804613805208.\n"
     ]
    }
   ],
   "source": [
    "def find_hyperparam(trial):\n",
    "    eta = trial.suggest_loguniform('eta', 0.001, 0.5)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 15)\n",
    "    #min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_loguniform('subsample', 0.1, 1.0)\n",
    "    sampling_method = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.1, 1.0)\n",
    "    xgbc = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                             eta = eta, \n",
    "                             num_boost_round = 999, \n",
    "                             early_stopping_rounds=10, \n",
    "                             max_depth = max_depth, \n",
    "                             #min_child_weight = min_child_weight, \n",
    "                             subsample = subsample, \n",
    "                             sampling_method = sampling_method, \n",
    "                             colsample_bytree = colsample_bytree)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train_res_scaled, y_train_res, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "xgb_study = optuna.create_study(direction='maximize')\n",
    "xgb_study.optimize(find_hyperparam, timeout = 60*60, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.761 / Test Accuracy:  0.671\n"
     ]
    }
   ],
   "source": [
    "# fitting and testing on the test set\n",
    "\n",
    "xgbc = xgb.XGBClassifier(**xgb_study.best_params, n_jobs= -1, verbosity=1)\n",
    "\n",
    "xgbc.fit(X_train_res_scaled, y_train_res)\n",
    "y_pred = xgbc.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.802 / Test Accuracy:  0.664\n",
    "# functional needs repair recall = 0.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top majority classes are doing so much better, but the minority class recall score dropped significantly from random forest model. We'll try to oversampling the minority classes and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving study\n",
    "#mod = open('PKL/xgb_study.pkl', 'wb')\n",
    "#pickle.dump(xgb_study, mod)\n",
    "#mod.close()\n",
    "# Reload the study\n",
    "#xgb_study = pickle.load(open('PKL/xgb_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#mod = open('PKL/xgbc_model.pkl', 'wb')\n",
    "#pickle.dump(xgbc, mod)\n",
    "#mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbc_model = pickle.load(open('PKL/xgbc_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "Now I will try to run a voting classifier using some of the above models. Since many of the models did better with with minority classes oversampled, I will use oversampled data for voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knc_g',\n",
       "                              KNeighborsClassifier(n_neighbors=3,\n",
       "                                                   weights='distance')),\n",
       "                             ('knc_study',\n",
       "                              KNeighborsClassifier(algorithm='kd_tree',\n",
       "                                                   leaf_size=12, n_neighbors=17,\n",
       "                                                   p=1, weights='distance')),\n",
       "                             ('knnSimple', KNeighborsClassifier(n_jobs=-1)),\n",
       "                             ('knnOptuna',\n",
       "                              KNeighborsClassifier(algorithm='kd_tree',\n",
       "                                                   leaf_size=25, n_neighbors=6,\n",
       "                                                   p=1)),\n",
       "                             ('dtcSimple',\n",
       "                              Dec...\n",
       "                              RandomForestClassifier(class_weight='balanced_subsample',\n",
       "                                                     criterion='entropy',\n",
       "                                                     max_depth=10,\n",
       "                                                     max_features=38,\n",
       "                                                     n_estimators=643,\n",
       "                                                     oob_score=True)),\n",
       "                             ('xgbc_model',\n",
       "                              XGBClassifier(colsample_bytree=0.20036919868049527,\n",
       "                                            eta=0.0057790380218066695,\n",
       "                                            max_depth=14, missing=nan,\n",
       "                                            n_jobs=-1,\n",
       "                                            objective='multi:softprob',\n",
       "                                            sampling_method='uniform',\n",
       "                                            subsample=0.9626562954673942))],\n",
       "                 n_jobs=-1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_c_all = VotingClassifier(estimators = [('knc_g', knc_g), \n",
    "                                          ('knc_study', knc_study), \n",
    "                                          ('knnSimple', knnSimple),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('dtcSimple', dtcSimple),\n",
    "                                          ('rf_model', rf_model),\n",
    "                                          ('xgbc_model', xgbc_model)\n",
    "                                         ], \n",
    "                            voting = 'hard', \n",
    "                           n_jobs = -1)\n",
    "voting_c_all.fit(X_train_res_scaled, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.756 / Test Accuracy:  0.66\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.82      0.81      4822\n",
      "functional needs repair       0.35      0.44      0.39       678\n",
      "         non functional       0.81      0.71      0.76      3410\n",
      "\n",
      "               accuracy                           0.75      8910\n",
      "              macro avg       0.65      0.66      0.65      8910\n",
      "           weighted avg       0.76      0.75      0.76      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_c_all.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.77 / Test Accuracy:  0.671\n",
    "# functional needs repair recall = 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall performance did not improve compare to random fores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "mod = open('PKL/voting_equal_full.pkl', 'wb')\n",
    "pickle.dump(voting_c_all, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "#voting_c_all = pickle.load(open('PKL/voting_equal_full.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Lasso Regularization\n",
    "Lastly we will look at running logistic regression with lasso penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLasso = LogisticRegression(penalty = 'l1', \n",
    "                                 tol = 0.0001, \n",
    "                                 C = 1, \n",
    "                                 solver='liblinear', \n",
    "                                 class_weight = 'balanced', \n",
    "                                 max_iter = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.313 / Test Accuracy:  0.553\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.97      0.05      0.09      4822\n",
      "functional needs repair       0.15      0.84      0.25       678\n",
      "         non functional       0.55      0.78      0.64      3410\n",
      "\n",
      "               accuracy                           0.39      8910\n",
      "              macro avg       0.56      0.55      0.33      8910\n",
      "           weighted avg       0.75      0.39      0.31      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogRegLasso.fit(X_train_res_scaled, y_train_res)\n",
    "y_pred_lasso = LogRegLasso.predict(X_test_scaled)\n",
    "scoring(y_test, y_pred_lasso)\n",
    "print(classification_report(y_test, y_pred_lasso))\n",
    "# Test F1 score:  0.68 / Test Accuracy:  0.695\n",
    "# functional needs repair recall = 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "mod = open('PKL/LogRegLasso.pkl', 'wb')\n",
    "pickle.dump(LogRegLasso, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Voting with Logistic Regression\n",
    "We will run the hard vote with logistic regression included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knc_g',\n",
       "                              KNeighborsClassifier(n_neighbors=3,\n",
       "                                                   weights='distance')),\n",
       "                             ('knc_study',\n",
       "                              KNeighborsClassifier(algorithm='kd_tree',\n",
       "                                                   leaf_size=12, n_neighbors=17,\n",
       "                                                   p=1, weights='distance')),\n",
       "                             ('knnSimple', KNeighborsClassifier(n_jobs=-1)),\n",
       "                             ('knnOptuna',\n",
       "                              KNeighborsClassifier(algorithm='kd_tree',\n",
       "                                                   leaf_size=25, n_neighbors=6,\n",
       "                                                   p=1)),\n",
       "                             ('dtcSimple',\n",
       "                              Dec...\n",
       "                                                     n_estimators=643,\n",
       "                                                     oob_score=True)),\n",
       "                             ('xgbc_model',\n",
       "                              XGBClassifier(colsample_bytree=0.20036919868049527,\n",
       "                                            eta=0.0057790380218066695,\n",
       "                                            max_depth=14, missing=nan,\n",
       "                                            n_jobs=-1,\n",
       "                                            objective='multi:softprob',\n",
       "                                            sampling_method='uniform',\n",
       "                                            subsample=0.9626562954673942)),\n",
       "                             ('LogRegLasso',\n",
       "                              LogisticRegression(C=1, class_weight='balanced',\n",
       "                                                 max_iter=300, penalty='l1',\n",
       "                                                 solver='liblinear'))],\n",
       "                 n_jobs=-1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_c_all2 = VotingClassifier(estimators = [('knc_g', knc_g), \n",
    "                                          ('knc_study', knc_study), \n",
    "                                          ('knnSimple', knnSimple),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('dtcSimple', dtcSimple),\n",
    "                                          ('rf_model', rf_model),\n",
    "                                          ('xgbc_model', xgbc_model),\n",
    "                                          ('LogRegLasso', LogRegLasso),\n",
    "                                         ], \n",
    "                            voting = 'hard', \n",
    "                           n_jobs = -1)\n",
    "voting_c_all2.fit(X_train_res_scaled, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.756 / Test Accuracy:  0.669\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.81      0.80      4822\n",
      "functional needs repair       0.35      0.47      0.40       678\n",
      "         non functional       0.81      0.72      0.76      3410\n",
      "\n",
      "               accuracy                           0.75      8910\n",
      "              macro avg       0.65      0.67      0.65      8910\n",
      "           weighted avg       0.76      0.75      0.76      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_c_all2.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/voting_equal_full2.pkl', 'wb')\n",
    "pickle.dump(voting_c_all2, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
