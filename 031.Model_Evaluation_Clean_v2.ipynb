{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "In this notebook, we will test multiple model and evaluate to choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "X = pd.read_pickle('PKL/X_train.pkl')\n",
    "y = pd.read_pickle('PKL/Y_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "We will split the train data once more. It's because this is a competition dataset and we actually don't have the 'test' score result. So we will use the test set we created from the initial training set as a holdout set to actually see our performance of the final model. The final test set, which we don't have the labels for, will be used to make a prediction in the final testing notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 13, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We will be utilizing mostly KNN and tree-based algorithms. We will first turn categorical features to binary dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning all categorical features to dummies \n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "# Check if training and testing sets have the same features\n",
    "if X_train.shape[1] != X_test.shape[1]:\n",
    "    print('only in train:', [x for x in X_train.columns if x not in X_test.columns])\n",
    "    print('only in test:',[x for x in X_test.columns if x not in X_train.columns])\n",
    "else: \n",
    "    print ('Good to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If they are not the same, add the column with 0s and fix the order\n",
    "# X_test[colname] = 0\n",
    "# X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance Issue\n",
    "Our dataset has high class imbalance issue. We will mostly deal with this by setting the class weight within each model, but in some cases where imbalance weight is not adequately dealt with by algorithm we test with resampled set using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Our target is multi-class with imbalance issue. To focus on the imbalance of minority classes, we will also look at the macro f1 score to capture the predictive performance for overall classes. It calculates the f1 score for each class and find the average so naturally take class imbalance into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, f1_score, accuracy_score, plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "To optimize the process, I will subset features based on a few random decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_feats = X_train.columns\n",
    "len(original_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, class_weight='balanced', random_state = 23)\n",
    "etc = etc.fit(X_train, y_train)\n",
    "model = SelectFromModel(etc, prefit=True, threshold = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = model.transform(X_train)\n",
    "new_feats = original_feats[model.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_new\n",
    "X_test = X_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "Since we will be testing kNN, all feature values need to be standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test= scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier\n",
    "We'll first create a dummy classifier as a baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.332 Test F1 score:  0.294 / Cohen Kappa:  -0.004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummyc = DummyClassifier(strategy = 'stratified') # using the default stratified strategy\n",
    "dummyc.fit(X_train, y_train)\n",
    "y_pred = dummyc.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'macro'), 3)\n",
    "ck_test = round(cohen_kappa_score(y_test, y_pred), 3)\n",
    "print('Accuracy: ', accuracy, 'Test F1 score: ', f1_test, '/ Cohen Kappa: ', ck_test)\n",
    "scorer['dummy'] = (accuracy, f1_test, ck_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.54      0.34      0.41      4822\n",
      "functional needs repair       0.07      0.29      0.11       678\n",
      "         non functional       0.38      0.34      0.36      3410\n",
      "\n",
      "               accuracy                           0.33      8910\n",
      "              macro avg       0.33      0.32      0.29      8910\n",
      "           weighted avg       0.44      0.33      0.37      8910\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(dummyc, X_test, y_test, xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stratified dummy classifier shows the weighted F1 score around .45 and less balanced accuracy. Dummy classifier is consistently wrong on all cases but recall for minority classes are especially bad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNearestNeighbors\n",
    "Now we will run K-Nearest Neighbors using GridSearchCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Function\n",
    "Function to return weighted F1 and balanced accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_test, y_pred, text, scorer = scorer):\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "    f1_test = round(f1_score(y_test, y_pred, average = 'macro'), 3)\n",
    "    ck_test = round(cohen_kappa_score(y_test, y_pred), 3)\n",
    "    print('Accuracy: ', accuracy, 'Test F1 score: ', f1_test, '/ Cohen Kappa: ', ck_test)\n",
    "    scorer[text] = (accuracy, f1_test, ck_test)\n",
    "    return scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal value for K using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': range(1, 16, 2), # setting K\n",
    "}\n",
    "\n",
    "knc = KNeighborsClassifier(weights = 'distance') \n",
    "knc_g = GridSearchCV(knc, params, cv = 5, scoring = 'f1_macro', verbose = 1, n_jobs = -1)\n",
    "knc_g.fit(X_train, y_train)\n",
    "print(knc_g.best_params_, ': ', knc_g.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN performance on the test set\n",
    "y_pred = knc_g.predict(X_test)\n",
    "scoring(y_test, y_pred, 'knn gridsearch')\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.741 / Test Accuracy:  0.622\n",
    "# Recall for functional needs repair: 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model \n",
    "mod = open('PKL/knn_gsc.pkl', 'wb')\n",
    "pickle.dump(knc_g.best_estimator_, mod)\n",
    "mod.close()\n",
    "# Reload the model\n",
    "#knc_g = pickle.load(open('PKL/knn_gsc.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with Optuna\n",
    "Now we want to try different optimization method to make sure we have the best hyperparmeter for KNN. This time we'll use optuna to explore even more hyperparameters. We'll cap the time to what it took to be same as the time it took to complete GridSearch above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hyperp_KNN(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 31)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    leaf_size = trial.suggest_int('leaf_size', 2, 60)\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "    knc = KNeighborsClassifier(weights = 'distance', \n",
    "                             n_neighbors = n_neighbors, \n",
    "                             algorithm = algorithm, \n",
    "                             leaf_size = leaf_size, \n",
    "                             p = p)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(knc, X_train, y_train, scoring = 'f1_macro', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "# initiating the optuna study\n",
    "knn_study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# optimization process\n",
    "knn_study.optimize(find_hyperp_KNN, timeout = 60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the study \n",
    "mod = open('PKL/knn_study.pkl', 'wb')\n",
    "pickle.dump(knn_study, mod)\n",
    "mod.close()\n",
    "# Reload the study\n",
    "#knn_study = pickle.load(open('PKL/knn_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the best params on the test set\n",
    "knc_opt = KNeighborsClassifier(**knn_study.best_params, weights = 'distance')\n",
    "knc_opt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knc_opt.predict(X_test)\n",
    "scoring(y_test, y_pred, 'knn optuna')\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.753 / Test Accuracy:  0.631\n",
    "# functional needs repair recall = 0.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score for the needs repair class is still low but the overall performance and the recall for non-functional improved slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "mod = open('PKL/knc_opt_model.pkl', 'wb')\n",
    "pickle.dump(knc_opt, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knc_study = pickle.load(open('PKL/knc_opt_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple kNN\n",
    "Running kNN with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnSimple = KNeighborsClassifier(n_jobs = -1, )\n",
    "knnSimple.fit(X_train, y_train)\n",
    "y_pred = knnSimple.predict(X_test)\n",
    "\n",
    "scoring(y_test, y_pred, 'knn_simple')\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.717 / Test Accuracy:  0.656\n",
    "# needs repair recall = 0.54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minority recall score has improved! let's try to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/knnSimple.pkl', 'wb')\n",
    "pickle.dump(knnSimple, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knnSimple = pickle.load(open('PKL/knnSimple.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Decision Trees\n",
    "Since we have a lot of features, tree-based model might deal better by ignoring less important features. We will first try with a simple tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcSimple = DecisionTreeClassifier(class_weight = 'balanced', max_depth=6)\n",
    "dtcSimple.fit(X_train, y_train)\n",
    "y_pred_dtcSimple = dtcSimple.predict(X_test)\n",
    "scoring(y_test, y_pred, 'decision tree simple')\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.728 / Test Accuracy:  0.642\n",
    "# functional needs repair recall = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "mod = open('PKL/dtcSimple.pkl', 'wb')\n",
    "pickle.dump(dtcSimple, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtcSimple = pickle.load(open('PKL/dtcSimple.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About similar performance as kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "We will run random forest optimized by Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hyperparam_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 700)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    class_weight = trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\n",
    "    max_features = trial.suggest_int('max_features', 2, 100)\n",
    "    min_weight_fraction_leaf = trial.suggest_loguniform('min_weight_fraction_leaf', 1e-7, 0.1)\n",
    "    max_leaf_nodes= trial.suggest_int('max_leaf_nodes', 10, 100)\n",
    "    rfc = RandomForestClassifier(oob_score = True, \n",
    "                                 n_estimators = n_estimators,\n",
    "                                 max_depth = max_depth, \n",
    "                                 min_samples_split = min_samples_split,\n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 criterion = criterion,\n",
    "                                 class_weight = class_weight, \n",
    "                                 max_features = max_features,\n",
    "                                 min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                 max_leaf_nodes = max_leaf_nodes\n",
    "                                )\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(rfc, X_train, y_train,\n",
    "                                    scoring = 'f1_macro', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "rfc_study = optuna.create_study(direction='maximize')\n",
    "rfc_study.optimize(find_hyperparam_rf, timeout = 60*30, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(oob_score = True, **rfc_study.best_params)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "scoring(y_test, y_pred, 'random forest optuna')\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.731 / Test Accuracy:  0.694\n",
    "# functional needs repair recall = 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better performance in predicting the positive minority cases even though overall F1 score has dropped slightly. This model seems to be weighing the minority recall better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the study\n",
    "mod = open('PKL/rfc_study.pkl', 'wb')\n",
    "pickle.dump(rfc_study, mod)\n",
    "mod.close()\n",
    "# Reload the study\n",
    "#rfc_study = pickle.load(open('PKL/rfc_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "mod = open('PKL/rf_model.pkl', 'wb')\n",
    "pickle.dump(rf, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_model = pickle.load(open('PKL/rf_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "rf_feats = pd.DataFrame(rf.feature_importances_,\n",
    "                        index = X_train.columns,\n",
    "                        columns=['feat_importance']).sort_values('feat_importance',ascending=False)\n",
    "rf_feats.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "Now we'll try to run XGBoost with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hyperparam(trial):\n",
    "    eta = trial.suggest_loguniform('eta', 0.001, 0.5)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 15)\n",
    "    #min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_loguniform('subsample', 0.1, 1.0)\n",
    "    sampling_method = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.1, 1.0)\n",
    "    xgbc = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                             eta = eta, \n",
    "                             num_boost_round = 999, \n",
    "                             early_stopping_rounds=10, \n",
    "                             max_depth = max_depth, \n",
    "                             #min_child_weight = min_child_weight, \n",
    "                             subsample = subsample, \n",
    "                             sampling_method = sampling_method, \n",
    "                             colsample_bytree = colsample_bytree)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train_res_scaled, y_train_res, scoring = 'balanced_accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "#xgb_study = optuna.create_study(direction='maximize')\n",
    "xgb_study.optimize(find_hyperparam, timeout = 60*60, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fitting and testing on the test set\n",
    "\n",
    "xgbc = xgb.XGBClassifier(**xgb_study.best_params, n_jobs= -1, verbosity=1)\n",
    "\n",
    "xgbc.fit(X_train_res_scaled, y_train_res)\n",
    "y_pred = xgbc.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:  0.802 / Test Accuracy:  0.664\n",
    "# functional needs repair recall = 0.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top majority classes are doing so much better, but the minority class recall score dropped significantly from random forest model. We'll try to oversampling the minority classes and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving study\n",
    "mod = open('PKL/xgb_study.pkl', 'wb')\n",
    "pickle.dump(xgb_study, mod)\n",
    "mod.close()\n",
    "# Reload the study\n",
    "#xgb_study = pickle.load(open('PKL/xgb_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "mod = open('PKL/xgbc_model.pkl', 'wb')\n",
    "pickle.dump(xgbc, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbc_model = pickle.load(open('PKL/xgbc_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "Now I will try to run a voting classifier using some of the above models. Since many of the models did better with with minority classes oversampled, I will use oversampled data for voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_c_all = VotingClassifier(estimators = [('knc_g', knc_g), \n",
    "                                          ('knc_opt', knc_opt),\n",
    "                                          ('knnSimple', knnSimple),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('dtcSimple', dtcSimple),\n",
    "                                          ('rf', rf),\n",
    "                                          ('xgbc', xgbc)\n",
    "                                         ], \n",
    "                            voting = 'soft', weights= [1, 1, 1, 1, 1, 2, 1],\n",
    "                           n_jobs = -1)\n",
    "voting_c_all.fit(X_train_res_scaled, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_c_all.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Test F1 score:  0.77 / Test Accuracy:  0.671\n",
    "# functional needs repair recall = 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall performance did not improve compare to random fores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "mod = open('PKL/voting_equal_full.pkl', 'wb')\n",
    "pickle.dump(voting_c_all, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "#voting_c_all = pickle.load(open('PKL/voting_equal_full.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Lasso Regularization\n",
    "Lastly we will look at running logistic regression with lasso penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparam(trial):\n",
    "    tol = trial.suggest_loguniform('tol', 1e-7, 1e-1)\n",
    "    C = trial.suggest_float('C', 0.0001, 1)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "    LogRegLasso = LogisticRegression(penalty = 'l1',\n",
    "                                     tol = 'tol',\n",
    "                                     C = 'C',\n",
    "                                     solver = 'solver',\n",
    "                                     max_iter = 'max_iter',\n",
    "                                     class_weight = 'balanced')\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train_res_scaled, y_train_res,\n",
    "                                    scoring = 'balanced_accuracy', cv = cv,\n",
    "                                    n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "#l1_study = optuna.create_study(direction='maximize')\n",
    "l1_study.optimize(find_hyperparam, timeout = 60*60, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting and testing on the test set\n",
    "\n",
    "l1_mod = LogisticRegression(**l1_study.best_params, n_jobs = -1, verbose= 1)\n",
    "\n",
    "l1_mod.fit(X_train_res_scaled, y_train_res)\n",
    "y_pred = l1_mod.predict(X_test_scaled)\n",
    "scoring(y_test, y_pred)\n",
    "# Test F1 score:   / Test Accuracy:\n",
    "# functional needs repair recall ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving study\n",
    "mod = open('PKL/l1_study.pkl', 'wb')\n",
    "pickle.dump(l1_study, mod)\n",
    "mod.close()\n",
    "\n",
    "# saving model\n",
    "mod = open('PKL/l1_mod.pkl', 'wb')\n",
    "pickle.dump(l1_mod, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Voting with Logistic Regression\n",
    "We will run the hard vote with logistic regression included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_c_all2 = VotingClassifier(estimators = [('knc_g', knc_g), \n",
    "                                          ('knc_opt', knc_opt),\n",
    "                                          ('knnSimple', knnSimple),\n",
    "                                          ('knnOptuna', knnOptuna),\n",
    "                                          ('dtcSimple', dtcSimple),\n",
    "                                          ('rf', rf),\n",
    "                                          ('xgbc', xgbc),\n",
    "                                          ('l1_mod', l1_mod),\n",
    "                                         ], \n",
    "                            voting = 'soft',\n",
    "                           n_jobs = -1)\n",
    "voting_c_all2.fit(X_train_res_scaled, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_c_all2.predict(X_test_scaled)    \n",
    "scoring(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/voting_equal_full2.pkl', 'wb')\n",
    "pickle.dump(voting_c_all2, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
