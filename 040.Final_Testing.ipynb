{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Testing\n",
    "\n",
    "In this notebook, we test the final model on a holdout set (set aside from competition training set) before we deploy our model for final submission. Also we create a prediction set from the competition test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import holdout test set\n",
    "X_train = pd.read_pickle('PKL/X_train.pkl')\n",
    "X_test = pd.read_pickle('PKL/X_test.pkl')\n",
    "y_test = pd.read_pickle('PKL/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding and standardization (if final model is KNN)\n",
    "X_train_ohe = pd.get_dummies(X_train)\n",
    "X_test_ohe = pd.get_dummies(X_test)\n",
    "\n",
    "# Check if they have the same features\n",
    "if X_train_ohe.shape[1] != X_test_ohe.shape[1]:\n",
    "    print([x for x in X_train_ohe.columns if x not in X_test_ohe.columns])\n",
    "    print([x for x in X_test_ohe.columns if x not in X_train_ohe.columns])\n",
    "else: \n",
    "    print ('Good to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "final_model = pickle.load(open('PKL/final_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and plot performance\n",
    "y_pred = final_model.predict(X_test_ohe)\n",
    "\n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'weighted'), 3)\n",
    "acc_test = round(balanced_accuracy_score(y_test, y_pred), 3)\n",
    "print('Test F1 score: ', f1_test, '/ Test Accuracy: ', acc_test)\n",
    "plot_confusion_matrix(dummyc, X_test_ohe, y_test, \n",
    "                      xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the full dataset\n",
    "X_full = pd.read_pickle('PKL/X_full.pkl')\n",
    "y_full = pd.read_pickle('PKL/y_full.pkl')\n",
    "X_full_ohe = pd.get_dummies(X_full)\n",
    "\n",
    "final_model.fit(X_full_ohe, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the final test set\n",
    "X_submission = pd.read_csv('DATA/TEST_VALUES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run preprocessing\n",
    "from preprocessing_pipeline import preprocessing\n",
    "\n",
    "X_submission_pp = preprocessing(X_submission)\n",
    "\n",
    "# one-hot-encoding and standardization (if final model is KNN)\n",
    "X_submission_ohe = pd.get_dummies(X_submission_pp)\n",
    "\n",
    "# Check if they have the same features\n",
    "if X_train_ohe.shape[1] != X_submission_ohe.shape[1]:\n",
    "    print([x for x in X_train_ohe.columns if x not in X_submission_ohe.columns])\n",
    "    print([x for x in X_submission_ohe.columns if x not in X_train_ohe.columns])\n",
    "else: \n",
    "    print ('Good to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and plot performance\n",
    "y_pred = final_model.predict(X_submission_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
