{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanzinian Water Pump Classification ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, SCORERS, balanced_accuracy_score, plot_confusion_matrix, classification_report\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Testing and Training Data From Cleaning and EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle('PKL/X_train.pkl')\n",
    "y = pd.read_pickle('PKL/y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 13, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dummies for Catergorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = pd.get_dummies(X_train)\n",
    "X_test_ohe = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in X_train.columns if x not in X_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in X_test.columns if x not in X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and resample the data\n",
    "#### Made X_train and X_test simple variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train_ohe)\n",
    "X_test = scale.transform(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Warm Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg with Lasso \n",
    "\n",
    "Should not have gone with liblinear likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLasso = LogisticRegression(penalty = 'l1', \n",
    "                                 tol = 0.0001, \n",
    "                                 C = 1, \n",
    "                                 solver='liblinear', \n",
    "                                 class_weight = 'balanced', \n",
    "                                 max_iter = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLasso.fit(X_train, y_train)\n",
    "y_pred_lasso = LogRegLasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6950883111100785\n",
      "Accuracy:  0.6796766163792803\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_lasso, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.65      0.73      4822\n",
      "functional needs repair       0.23      0.71      0.35       678\n",
      "         non functional       0.77      0.68      0.72      3410\n",
      "\n",
      "               accuracy                           0.67      8910\n",
      "              macro avg       0.61      0.68      0.60      8910\n",
      "           weighted avg       0.76      0.67      0.70      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/LogRegLasso.pkl', 'wb')\n",
    "pickle.dump(LogRegLasso, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Lasso using Saga Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#('LogRegSaga', LogRegSaga) not working in voting class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegSaga = LogisticRegression(penalty = 'l1', \n",
    "                             tol = 0.001, \n",
    "                             C = 1, \n",
    "                             class_weight = 'balanced', \n",
    "                             solver ='saga', \n",
    "                             max_iter = 2000, \n",
    "                             n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegSaga.fit(X_train, y_train)\n",
    "LogRegSaga = LogRegSaga.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6980744773870491\n",
      "Accuracy:  0.6857248195477808\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, LogRegSaga, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, LogRegSaga))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.83      0.65      0.73      4822\n",
      "functional needs repair       0.24      0.72      0.36       678\n",
      "         non functional       0.77      0.68      0.72      3410\n",
      "\n",
      "               accuracy                           0.67      8910\n",
      "              macro avg       0.61      0.69      0.60      8910\n",
      "           weighted avg       0.76      0.67      0.70      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,LogRegSaga))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is actually lasso\n",
    "mod = open('PKL/LogRegSaga.pkl', 'wb')\n",
    "pickle.dump(LogRegSaga, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using Sag Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegSag = LogisticRegression(penalty = 'l2', \n",
    "                             tol = 0.0001, \n",
    "                             C = 1, \n",
    "                             class_weight = 'balanced', \n",
    "                             multi_class = 'multinomial',\n",
    "                             solver ='sag', \n",
    "                             max_iter = 2000, \n",
    "                             n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegSag.fit(X_train, y_train)\n",
    "y_pred_LogRegSag = LogRegSag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6956002179446611\n",
      "Accuracy:  0.6800795026292921\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_LogRegSag, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_LogRegSag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.65      0.73      4822\n",
      "functional needs repair       0.23      0.71      0.35       678\n",
      "         non functional       0.77      0.68      0.72      3410\n",
      "\n",
      "               accuracy                           0.67      8910\n",
      "              macro avg       0.61      0.68      0.60      8910\n",
      "           weighted avg       0.76      0.67      0.70      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_LogRegSag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/LogRegSag.pkl', 'wb')\n",
    "pickle.dump(LogRegSag, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using Newton C Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegNewton = LogisticRegression(penalty = 'l2', \n",
    "                             tol = 0.0001, \n",
    "                             C = 1, \n",
    "                             class_weight = 'balanced', \n",
    "                             solver ='newton-cg', \n",
    "                             max_iter = 1000, \n",
    "                             n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegNewton.fit(X_train, y_train)\n",
    "y_pred_LogRegNewton = LogRegNewton.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6954784709373352\n",
      "Accuracy:  0.6799817509186371\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_LogRegNewton, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_LogRegNewton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.65      0.73      4822\n",
      "functional needs repair       0.23      0.71      0.35       678\n",
      "         non functional       0.77      0.68      0.72      3410\n",
      "\n",
      "               accuracy                           0.67      8910\n",
      "              macro avg       0.61      0.68      0.60      8910\n",
      "           weighted avg       0.76      0.67      0.70      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_LogRegNewton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/LogRegNewton.pkl', 'wb')\n",
    "pickle.dump(LogRegNewton, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Lbfgs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLb = LogisticRegression(penalty = 'l2', \n",
    "                             tol = 0.0001, \n",
    "                             C = 1, \n",
    "                             multi_class = 'multinomial',\n",
    "                             solver ='lbfgs',\n",
    "                              class_weight = 'balanced', \n",
    "                             max_iter = 2000, \n",
    "                             n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLb.fit(X_train, y_train)\n",
    "y_pred_LogRegLb = LogRegLb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6957219517904653\n",
      "Accuracy:  0.6801772543399469\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_LogRegLb, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_LogRegLb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.65      0.73      4822\n",
      "functional needs repair       0.23      0.71      0.35       678\n",
      "         non functional       0.77      0.68      0.72      3410\n",
      "\n",
      "               accuracy                           0.67      8910\n",
      "              macro avg       0.61      0.68      0.60      8910\n",
      "           weighted avg       0.76      0.67      0.70      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_LogRegLb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/LogRegLb.pkl', 'wb')\n",
    "pickle.dump(LogRegLb, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6947864442358115\n",
      "Accuracy:  0.6794692335505785\n"
     ]
    }
   ],
   "source": [
    "LogReg = LogisticRegression(solver='liblinear',\n",
    "                            class_weight = 'balanced', \n",
    "                            max_iter = 200,\n",
    "                            n_jobs = -1)\n",
    "\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_pred_logreg = LogReg.predict(X_test)\n",
    "\n",
    "print('F1: ', f1_score(y_test, y_pred_logreg, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.65      0.73      4822\n",
      "functional needs repair       0.23      0.71      0.35       678\n",
      "         non functional       0.77      0.68      0.72      3410\n",
      "\n",
      "               accuracy                           0.66      8910\n",
      "              macro avg       0.61      0.68      0.60      8910\n",
      "           weighted avg       0.76      0.66      0.69      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/LogReg.pkl', 'wb')\n",
    "pickle.dump(LogReg, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN \n",
    "First I will start with a simple KNN. \n",
    "Then we will use Optuna to run and attempt to find the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnSimple = KNeighborsClassifier(n_neighbors = 5, \n",
    "                                 p = 2, \n",
    "                                 n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnSimple.fit(X_train, y_train)\n",
    "y_pred_knnSimple = knnSimple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.71711628105347\n",
      "Accuracy:  0.6562379215275892\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_knnSimple, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_knnSimple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.72      0.76      4822\n",
      "functional needs repair       0.28      0.54      0.37       678\n",
      "         non functional       0.74      0.71      0.73      3410\n",
      "\n",
      "               accuracy                           0.70      8910\n",
      "              macro avg       0.61      0.66      0.62      8910\n",
      "           weighted avg       0.74      0.70      0.72      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_knnSimple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Knn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/knnSimple.pkl', 'wb')\n",
    "pickle.dump(knnSimple, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KNN with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_objective(trial): \n",
    "    knn_neighbors = trial.suggest_int('n_neighbors', 1,10) \n",
    "    knn_p = trial.suggest_categorical('p', [1, 2])\n",
    "    knn_leaf_size = trial.suggest_int('leaf_size', 2, 50)\n",
    "    knn_algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = knn_neighbors, \n",
    "                               p = knn_p, \n",
    "                               leaf_size = knn_leaf_size,\n",
    "                                algorithm =  knn_algorithm)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_optuna = knn.predict(X_test)\n",
    "    return (1 - f1_score(y_test, y_pred_optuna, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-20 08:10:02,743] Trial 0 finished with value: 0.2525007574872148 and parameters: {'n_neighbors': 6, 'p': 1, 'leaf_size': 38, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.2525007574872148.\n",
      "[I 2020-08-20 08:29:52,961] Trial 1 finished with value: 0.26217077385548193 and parameters: {'n_neighbors': 10, 'p': 1, 'leaf_size': 18, 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.2525007574872148.\n",
      "[I 2020-08-20 09:02:01,508] Trial 2 finished with value: 0.24328000217342982 and parameters: {'n_neighbors': 2, 'p': 1, 'leaf_size': 6, 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.24328000217342982.\n",
      "[I 2020-08-20 09:14:35,998] Trial 3 finished with value: 0.2640357918244377 and parameters: {'n_neighbors': 9, 'p': 1, 'leaf_size': 30, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.24328000217342982.\n",
      "[I 2020-08-20 09:19:49,937] Trial 4 finished with value: 0.2736111234120412 and parameters: {'n_neighbors': 5, 'p': 2, 'leaf_size': 50, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.24328000217342982.\n",
      "[I 2020-08-20 09:24:32,935] Trial 5 finished with value: 0.28291761109090807 and parameters: {'n_neighbors': 7, 'p': 2, 'leaf_size': 23, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.24328000217342982.\n",
      "[I 2020-08-20 09:38:41,208] Trial 6 finished with value: 0.2629344709939757 and parameters: {'n_neighbors': 3, 'p': 2, 'leaf_size': 30, 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.24328000217342982.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(knn_objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7419922123377675\n",
      "Accuracy:  0.6245697927096333\n"
     ]
    }
   ],
   "source": [
    "#Best is trial 2 of 6 with value: 0.24328000217342982\n",
    "\n",
    "knnOptuna = KNeighborsClassifier(n_neighbors = 2, \n",
    "                                 p = 1, \n",
    "                                 leaf_size = 6, \n",
    "                                 algorithm = 'kd_tree', \n",
    "                                 n_jobs = -1)\n",
    "knnOptuna.fit(X_train, y_train)\n",
    "y_pred_knnOptuna = knnOptuna.predict(X_test)\n",
    "print('F1: ', f1_score(y_test, y_pred_knnOptuna, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_knnOptuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.75      0.88      0.81      4822\n",
      "functional needs repair       0.37      0.36      0.36       678\n",
      "         non functional       0.84      0.64      0.72      3410\n",
      "\n",
      "               accuracy                           0.75      8910\n",
      "              macro avg       0.65      0.62      0.63      8910\n",
      "           weighted avg       0.75      0.75      0.74      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_knnOptuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/knnOptuna.pkl', 'wb')\n",
    "pickle.dump(knnOptuna, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7419922123377675\n",
      "Accuracy:  0.6245697927096333\n"
     ]
    }
   ],
   "source": [
    "knnOptuna2 = KNeighborsClassifier(n_neighbors = 2, \n",
    "                                 p = 1, \n",
    "                                 leaf_size = 17, \n",
    "                                 algorithm = 'kd_tree', \n",
    "                                 n_jobs = -1)\n",
    "knnOptuna2.fit(X_train, y_train)\n",
    "y_pred_knnOptuna2 = knnOptuna2.predict(X_test)\n",
    "print('F1: ', f1_score(y_test, y_pred_knnOptuna2, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_knnOptuna2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.75      0.88      0.81      4822\n",
      "functional needs repair       0.37      0.36      0.36       678\n",
      "         non functional       0.84      0.64      0.72      3410\n",
      "\n",
      "               accuracy                           0.75      8910\n",
      "              macro avg       0.65      0.62      0.63      8910\n",
      "           weighted avg       0.75      0.75      0.74      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_knnOptuna2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/knnOptuna2.pkl', 'wb')\n",
    "pickle.dump(knnOptuna2, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnOptuna3 = KNeighborsClassifier(n_neighbors = 7, \n",
    "                                 p = 1, \n",
    "                                 leaf_size = 42, \n",
    "                                  weights = 'distance',\n",
    "                                 algorithm = 'brute', \n",
    "                                 n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnOptuna3.fit(X_train, y_train)\n",
    "y_pred_knnOptuna3 = knnOptuna3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7484392132533673\n",
      "Accuracy:  0.6578040677135095\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_knnOptuna3, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_knnOptuna3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.78      0.79      4822\n",
      "functional needs repair       0.34      0.44      0.38       678\n",
      "         non functional       0.76      0.75      0.76      3410\n",
      "\n",
      "               accuracy                           0.74      8910\n",
      "              macro avg       0.64      0.66      0.64      8910\n",
      "           weighted avg       0.75      0.74      0.75      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_knnOptuna3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/knnOptuna3.pkl', 'wb')\n",
    "pickle.dump(knnOptuna3, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting with a few simple decision trees, then expant to Optuna to find a better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcSimple = DecisionTreeClassifier(criterion = 'gini', max_depth = 20, random_state = 1, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcSimple.fit(X_train, y_train)\n",
    "y_pred_dtcSimple = dtcSimple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7284391075730546\n",
      "Accuracy:  0.642285014506644\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_dtcSimple, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_dtcSimple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.78      0.77      0.77      4822\n",
      "functional needs repair       0.30      0.45      0.36       678\n",
      "         non functional       0.77      0.71      0.74      3410\n",
      "\n",
      "               accuracy                           0.72      8910\n",
      "              macro avg       0.62      0.64      0.62      8910\n",
      "           weighted avg       0.74      0.72      0.73      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dtcSimple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/dtcSimple.pkl', 'wb')\n",
    "pickle.dump(dtcSimple, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtc_objective(trial): \n",
    "    dtc_criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    dtc_splitter = trial.suggest_categorical('n_neighbors', ['best', 'random']) \n",
    "    dtc_maxdepth = trial.sugguest_int('max_depth', 1,10)\n",
    "    dtc_maxfeatures = trial.suggest_int('max_features', .01, .7)\n",
    "    \n",
    "    dtc = DecisionTreeClassifier(criterion = dtc_criterion, \n",
    "                                 splitter = dtc_splitter, \n",
    "                                 max_depth = dtc_maxdepth, \n",
    "                                 max_features = dtc_maxfeatures, \n",
    "                                class_weight = 'balanced')\n",
    "    \n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred_dtc= dtc.predict(X_test)\n",
    "    return (1 - f1_score(y_test, y_pred_dtc, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(dtc_objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcOptuna = DecisionTreeClassifier(criterion = 'gini', \n",
    "                                 splitter = 'random', \n",
    "                                 max_depth = 10, \n",
    "                                 max_features = 'sqrt', \n",
    "                                class_weight = 'balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcOptuna.fit(X_train, y_train)\n",
    "y_pred_dtcOptuna = dtcOptuna.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6032149770407131\n",
      "Accuracy:  0.5466137640214893\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_dtcOptuna, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_dtcOptuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.71      0.63      0.66      4822\n",
      "functional needs repair       0.19      0.47      0.27       678\n",
      "         non functional       0.63      0.54      0.58      3410\n",
      "\n",
      "               accuracy                           0.58      8910\n",
      "              macro avg       0.51      0.55      0.51      8910\n",
      "           weighted avg       0.64      0.58      0.60      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dtcOptuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/dtcOptuna.pkl', 'wb')\n",
    "pickle.dump(dtcOptuna, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest classifer, then expanded to test optuna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcSimple = RandomForestClassifier(random_state = 1, \n",
    "                                   n_estimators = 500, \n",
    "                                   max_depth = 3, \n",
    "                                   max_features = .3, \n",
    "                                   class_weight = 'balanced_subsample', \n",
    "                                   criterion = 'gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcSimple.fit(X_train, y_train)\n",
    "y_pred_rfcSimple = rfcSimple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6463530464336945\n",
      "Accuracy:  0.5665821264567874\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_rfcSimple, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_rfcSimple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.69      0.79      0.74      4822\n",
      "functional needs repair       0.19      0.46      0.27       678\n",
      "         non functional       0.86      0.45      0.59      3410\n",
      "\n",
      "               accuracy                           0.63      8910\n",
      "              macro avg       0.58      0.57      0.53      8910\n",
      "           weighted avg       0.72      0.63      0.65      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rfcSimple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/rfcSimple.pkl', 'wb')\n",
    "pickle.dump(rfcSimple, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial): \n",
    "    rfc_max_depth = trial.suggest_int('max_depth', 5,10)\n",
    "    rfc_n_estimators = trial.suggest_int('n_estimators', 300, 700) \n",
    "    rfc_max_features = trial.suggest_loguniform('max_features', .001, .2)\n",
    "    rfc_criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    rfc = RandomForestClassifier(random_state = 1, max_depth = rfc_max_depth, n_estimators = rfc_n_estimators,\n",
    "                                 max_features = rfc_max_features, criterion = rfc_criterion, class_weight = 'balanced')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred_optuna = rfc.predict(X_test)\n",
    "    return (1 - f1_score(y_test, y_pred_optuna, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rfc Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.733414442080737\n",
      "Accuracy:  0.6809539623754565\n"
     ]
    }
   ],
   "source": [
    "rfc_Optuna = RandomForestClassifier(random_state = 1, \n",
    "                                    n_estimators = 572, \n",
    "                                    max_depth = 10, \n",
    "                                   max_features = 0.06602383170294993, \n",
    "                                    class_weight = 'balanced', \n",
    "                                    criterion = 'gini')\n",
    "rfc_Optuna.fit(X_train, y_train)\n",
    "y_pred_Optuna = rfc_Optuna.predict(X_test)\n",
    "print('F1: ', f1_score(y_test, y_pred_Optuna, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_Optuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.78      0.78      4822\n",
      "functional needs repair       0.28      0.62      0.38       678\n",
      "         non functional       0.84      0.65      0.73      3410\n",
      "\n",
      "               accuracy                           0.72      8910\n",
      "              macro avg       0.64      0.68      0.63      8910\n",
      "           weighted avg       0.77      0.72      0.73      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_Optuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/rfc_Optuna.pkl', 'wb')\n",
    "pickle.dump(rfc_Optuna, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rfc Optuna 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7321537448880838\n",
      "Accuracy:  0.6811399686813578\n"
     ]
    }
   ],
   "source": [
    "rfc_Optuna2 = RandomForestClassifier(random_state = 1, \n",
    "                                     n_estimators = 362, \n",
    "                                     max_depth = 10, \n",
    "                                     max_features = 0.0554940476012136275, \n",
    "                                     class_weight = 'balanced', \n",
    "                                     criterion = 'gini')\n",
    "\n",
    "rfc_Optuna2.fit(X_train, y_train)\n",
    "y_pred_Optuna2 = rfc_Optuna2.predict(X_test)\n",
    "\n",
    "print('F1: ', f1_score(y_test, y_pred_Optuna2, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_Optuna2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.76      0.78      4822\n",
      "functional needs repair       0.28      0.61      0.38       678\n",
      "         non functional       0.82      0.67      0.74      3410\n",
      "\n",
      "               accuracy                           0.72      8910\n",
      "              macro avg       0.63      0.68      0.63      8910\n",
      "           weighted avg       0.77      0.72      0.73      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_Optuna2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/rfc_Optuna2.pkl', 'wb')\n",
    "pickle.dump(rfc_Optuna2, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(14,100))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values)\n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_feature_importances(rfc_Optuna2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparam(trial):\n",
    "    eta = trial.suggest_float('eta', 0.001, 0.5)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_float('subsample', 0.1, 1.0)\n",
    "    sampling_method = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n",
    "    num_parallel_tree = trial.suggest_int('num_parallel_tree', 1, 10)\n",
    "    \n",
    "    xgbc = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                             eta = eta, \n",
    "                             num_boost_round = 999, \n",
    "                             early_stopping_rounds=10, \n",
    "                             max_depth = max_depth, \n",
    "                             min_child_weight = min_child_weight, \n",
    "                             subsample = subsample, \n",
    "                             sampling_method = sampling_method, \n",
    "                             colsample_bytree = colsample_bytree, \n",
    "                            num_parallel_tree = num_parallel_tree)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train_ohe, y_train, scoring = 'f1_weighted', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "#xgb_study = optuna.create_study(direction='maximize')\n",
    "#xgb_study.optimize(find_hyperparam, timeout = 12600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('LogRegLasso',\n",
       "  LogisticRegression(C=1, class_weight='balanced', max_iter=300, penalty='l1',\n",
       "                     solver='liblinear')),)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                               ('knn', knnSimple), ('LogRegSaga', LogRegSaga), ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = VotingClassifier( estimators= [('LogRegLasso', LogRegLasso),\n",
    "                                      ('LogReg', LogReg),\n",
    "                                      ('LogRegNewton', LogRegNewton),\n",
    "                                      \n",
    "                                      ('LogRegSag', LogRegSag),\n",
    "                                      ('LogRegLb', LogRegLb),\n",
    "                                      \n",
    "                                    \n",
    "                                      ('knnOptuna', knnOptuna),\n",
    "                                      ('knnOptuna2', knnOptuna2),\n",
    "                                      \n",
    "                                      ('dtcSimple', dtcSimple),\n",
    "                                      ('dtcOptuna', dtcOptuna),\n",
    "                                      \n",
    "                                      ('rfc_Optuna', rfc_Optuna),\n",
    "                                      ('rfc_Optuna2', rfc_Optuna2)], \n",
    "                                        \n",
    "                        voting='hard')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote.fit(X_train, y_train)\n",
    "y_pred_vote = vote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_vote, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/vote.pkl', 'wb')\n",
    "pickle.dump(vote, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = VotingClassifier( estimators= [('LogRegLasso', LogRegLasso),\n",
    "                                      ('LogReg', LogReg),\n",
    "                                      ('LogRegNewton', LogRegNewton),\n",
    "                                      ('LogRegSaga', LogRegSaga),\n",
    "                                      ('LogRegSag', LogRegSag),\n",
    "                                      ('LogRegLb', LogRegLb)],\n",
    "                        voting='hard', n_jobs = -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote.fit(X_train, y_train)\n",
    "y_pred_vote = vote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_vote, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
