{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanzinian Water Pump Classification ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, SCORERS, balanced_accuracy_score\n",
    "\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Testing and Training Data From Cleaning and EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle('PKL/X_train.pkl')\n",
    "y = pd.read_pickle('PKL/y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 13, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train. urban_lga = X_train. urban_lga.astype(int)\n",
    "#X_test. urban_lga = X_test. urban_lga.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.rural_lga = X_train.rural_lga.astype(int)\n",
    "#X_test.rural_lga = X_test.rural_lga.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.urban_wards = X_train.urban_wards.astype(int)\n",
    "#X_test.urban_wards = X_test.urban_wards.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.rural_wards = X_train.rural_wards.astype(int)\n",
    "#X_test.rural_wards = X_test.rural_wards.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.public_meeting = X_train.public_meeting.astype(int)\n",
    "#X_test.public_meeting = X_test.public_meeting.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.permit = X_train.permit.astype(int)\n",
    "#X_test.permit = X_test.permit.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dummies for Catergorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = pd.get_dummies(X_train)\n",
    "X_test_ohe = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in X_train.columns if x not in X_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in X_test.columns if x not in X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and resample the data\n",
    "#### Made X_train and X_test simple variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train_ohe)\n",
    "X_test = scale.transform(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Warm Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg with Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLasso = LogisticRegression(penalty = 'l1', \n",
    "                                 tol = 0.0001, \n",
    "                                 C = 1, \n",
    "                                 solver='liblinear', \n",
    "                                 class_weight = 'balanced', \n",
    "                                 max_iter = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegLasso.fit(X_train, y_train)\n",
    "y_pred_lasso = LogRegLasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_lasso, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/LogRegLasso.pkl', 'wb')\n",
    "pickle.dump(LogRegLasso, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg = LogisticRegression(solver='liblinear',\n",
    "                            class_weight = 'balanced', \n",
    "                            max_iter = 200)\n",
    "\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_pred_logreg = LogReg.predict(X_test)\n",
    "\n",
    "print('F1: ', f1_score(y_test, y_pred_logreg, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/LogReg.pkl', 'wb')\n",
    "pickle.dump(LogReg, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN \n",
    "First I will start with a simple KNN. \n",
    "Then we will use Optuna to run and attempt to find the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnSimple = KNeighborsClassifier(n_neighbors = 5, \n",
    "                                 p = 2, \n",
    "                                 n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnSimple.fit(X_train, y_train)\n",
    "y_pred_knnSimple = knnSimple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_knnSimple, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_knnSimple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Knn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/knnSimple.pkl', 'wb')\n",
    "pickle.dump(knnSimple, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KNN with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_objective(trial): \n",
    "    knn_neighbors = trial.suggest_int('n_neighbors', 1,10) \n",
    "    knn_p = trial.suggest_categorical('p', [1, 2])\n",
    "    knn_leaf_size = trial.suggest_int('leaf_size', 2, 50)\n",
    "    knn_algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = knn_neighbors, \n",
    "                               p = knn_p, \n",
    "                               leaf_size = knn_leaf_size,\n",
    "                                algorithm =  knn_algorithm)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_optuna = knn.predict(X_test)\n",
    "    return (1 - f1_score(y_test, y_pred_optuna, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-20 08:10:02,743] Trial 0 finished with value: 0.2525007574872148 and parameters: {'n_neighbors': 6, 'p': 1, 'leaf_size': 38, 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.2525007574872148.\n",
      "[I 2020-08-20 08:29:52,961] Trial 1 finished with value: 0.26217077385548193 and parameters: {'n_neighbors': 10, 'p': 1, 'leaf_size': 18, 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.2525007574872148.\n",
      "[I 2020-08-20 09:02:01,508] Trial 2 finished with value: 0.24328000217342982 and parameters: {'n_neighbors': 2, 'p': 1, 'leaf_size': 6, 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.24328000217342982.\n",
      "[I 2020-08-20 09:14:35,998] Trial 3 finished with value: 0.2640357918244377 and parameters: {'n_neighbors': 9, 'p': 1, 'leaf_size': 30, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.24328000217342982.\n",
      "[I 2020-08-20 09:19:49,937] Trial 4 finished with value: 0.2736111234120412 and parameters: {'n_neighbors': 5, 'p': 2, 'leaf_size': 50, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.24328000217342982.\n",
      "[I 2020-08-20 09:24:32,935] Trial 5 finished with value: 0.28291761109090807 and parameters: {'n_neighbors': 7, 'p': 2, 'leaf_size': 23, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.24328000217342982.\n",
      "[I 2020-08-20 09:38:41,208] Trial 6 finished with value: 0.2629344709939757 and parameters: {'n_neighbors': 3, 'p': 2, 'leaf_size': 30, 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.24328000217342982.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(knn_objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7416161415456416\n",
      "Accuracy:  0.6257424679552516\n"
     ]
    }
   ],
   "source": [
    "#Best is trial 2 of 6 with value: 0.24328000217342982\n",
    "\n",
    "knnOptuna = KNeighborsClassifier(n_neighbors = 2, \n",
    "                                 p = 1, \n",
    "                                 leaf_size = 6, \n",
    "                                 algorithm = 'kd_tree', \n",
    "                                 n_jobs = -1)\n",
    "knnOptuna.fit(X_train, y_train)\n",
    "y_pred_knnOptuna = knnOptuna.predict(X_test)\n",
    "print('F1: ', f1_score(y_test, y_pred_knnOptuna, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_knnOptuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/knnOptuna.pkl', 'wb')\n",
    "pickle.dump(knnOptuna, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting with a few simple decision trees, then expant to Optuna to find a better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcSimple = DecisionTreeClassifier(criterion = 'gini', max_depth = 20, random_state = 1, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcSimple.fit(X_train, y_train)\n",
    "y_pred_dtcSimple = dtcSimple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7483997194651338\n",
      "Accuracy:  0.6655886434850676\n"
     ]
    }
   ],
   "source": [
    "print('F1: ', f1_score(y_test, y_pred_dtcSimple, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_dtcSimple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/dtcSimple.pkl', 'wb')\n",
    "pickle.dump(dtcSimple, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtc_objective(trial): \n",
    "    dtc_criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    dtc_splitter = trial.suggest_categorical('n_neighbors', ['best', 'random']) \n",
    "    dtc_maxdepth = trial.sugguest_int('max_depth', 1,10)\n",
    "    dtc_maxfeatures = trial.suggest_int('max_features', .01, .7)\n",
    "    \n",
    "    dtc = DecisionTreeClassifier(criterion = dtc_criterion, \n",
    "                                 splitter = dtc_splitter, \n",
    "                                 max_depth = dtc_maxdepth, \n",
    "                                 max_features = dtc_maxfeatures, \n",
    "                                class_weight = 'balanced')\n",
    "    \n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred_dtc= dtc.predict(X_test)\n",
    "    return (1 - f1_score(y_test, y_pred_dtc, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(dtc_objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcOptuna = DecissionTreeClassifer()\n",
    "dtcOptuna.fit(X_train,y_train)\n",
    "y_pred_dtcOptuna = knnOptuna.predict(X_test)\n",
    "\n",
    "print('F1: ', f1_score(y_test, y_pred_dtcOptuna, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_dtcOptuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/dtcOptuna.pkl', 'wb')\n",
    "pickle.dump(dtcOptuna, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest classifer, then expanded to test optuna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.6509321696322655\n",
      "Accuracy:  0.5659164915441665\n"
     ]
    }
   ],
   "source": [
    "rfcSimple = RandomForestClassifier(random_state = 1, \n",
    "                                   n_estimators = 500, \n",
    "                                   max_depth = 3, \n",
    "                                   max_features = .3, \n",
    "                                   class_weight = 'balanced_subsample', \n",
    "                                   criterion = 'gini')\n",
    "rfcSimple.fit(X_train, y_train)\n",
    "y_pred_rfcSimple = rfcSimple.predict(X_test)\n",
    "\n",
    "print('F1: ', f1_score(y_test, y_pred_rfcSimple, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_rfcSimple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/rfcSimple.pkl', 'wb')\n",
    "pickle.dump(rfcSimple, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial): \n",
    "    rfc_max_depth = trial.suggest_int('max_depth', 5,10)\n",
    "    rfc_n_estimators = trial.suggest_int('n_estimators', 300, 700) \n",
    "    rfc_max_features = trial.suggest_loguniform('max_features', .001, .2)\n",
    "    rfc_criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    rfc = RandomForestClassifier(random_state = 1, max_depth = rfc_max_depth, n_estimators = rfc_n_estimators,\n",
    "                                 max_features = rfc_max_features, criterion = rfc_criterion, class_weight = 'balanced')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred_optuna = rfc.predict(X_test)\n",
    "    return (1 - f1_score(y_test, y_pred_optuna, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rfc Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.732407520823967\n",
      "Accuracy:  0.690361197169631\n"
     ]
    }
   ],
   "source": [
    "rfc_Optuna = RandomForestClassifier(random_state = 1, \n",
    "                                    n_estimators = 572, \n",
    "                                    max_depth = 10, \n",
    "                                   max_features = 0.06602383170294993, \n",
    "                                    class_weight = 'balanced', \n",
    "                                    criterion = 'gini')\n",
    "rfc_Optuna.fit(X_train, y_train)\n",
    "y_pred_Optuna = rfc_Optuna.predict(X_test)\n",
    "print('F1: ', f1_score(y_test, y_pred_Optuna, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_Optuna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/rfc_Optuna.pkl', 'wb')\n",
    "pickle.dump(rfc_Optuna, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rfc Optuna 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.732407520823967\n",
      "Accuracy:  0.690361197169631\n"
     ]
    }
   ],
   "source": [
    "rfc_Optuna2 = RandomForestClassifier(random_state = 1, n_estimators = 572, \n",
    "                                     max_depth = 10, \n",
    "                                     max_features = 0.06602383170294993, \n",
    "                                     class_weight = 'balanced', \n",
    "                                     criterion = 'gini')\n",
    "\n",
    "rfc_Optuna2.fit(X_train, y_train)\n",
    "y_pred_Optuna2 = rfc_Optuna2.predict(X_test)\n",
    "\n",
    "print('F1: ', f1_score(y_test, y_pred_Optuna2, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_Optuna2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/rfc_Optuna2.pkl', 'wb')\n",
    "pickle.dump(rfc_Optuna2, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(14,100))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values)\n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(rfc_Optuna2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7768854652814526\n",
      "Accuracy:  0.711696480003709\n"
     ]
    }
   ],
   "source": [
    "vote = VotingClassifier( estimators= [('knn', knnSimple),\n",
    "                                      ('knnOptuna', knnOptuna),\n",
    "                                      ('dtcSimple', dtcSimple),\n",
    "                                      ('rfc_Optuna2', rfc_Optuna2), \n",
    "                                      ('rfc_Optuna', rfc_Optuna)], \n",
    "                                        voting='hard')\n",
    "\n",
    "vote.fit(X_train, y_train)\n",
    "y_pred_vote = vote.predict(X_test)\n",
    "\n",
    "print('F1: ', f1_score(y_test, y_pred_vote, average = 'weighted'))\n",
    "print('Accuracy: ', balanced_accuracy_score(y_test, y_pred_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = open('PKL/vote.pkl', 'wb')\n",
    "pickle.dump(vote, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
